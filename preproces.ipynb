{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:02.909833700Z",
     "start_time": "2024-11-24T07:12:02.841743300Z"
    }
   },
   "cell_type": "code",
   "source": "val onlyExport = true",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:12.742494900Z",
     "start_time": "2024-11-24T07:12:02.914836400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%use serialization\n",
    "%use dataframe\n",
    "%use coroutines\n",
    "@file:DependsOn(\"com.vladsch.flexmark:flexmark-all:0.64.8\")\n",
    "@file:DependsOn(\"org.apache.commons:commons-compress:1.26.1\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:12.852174700Z",
     "start_time": "2024-11-24T07:12:12.760515500Z"
    }
   },
   "source": "print(\"Hola!\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hola!"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:13.115324700Z",
     "start_time": "2024-11-24T07:12:12.858171500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.io.File\n",
    "\n",
    "// read all files in the `datasets` directory\n",
    "val files = File(\"./datasets\").listFiles()!!.map { it.name }\n",
    "files"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[009.전문분야_기술과학_한국어 멀티세션 데이터, 010.전문분야_사회과학_한국어 멀티세션 데이터, 016.행정 문서 대상 기계독해 데이터, 017.뉴스 기사 기계독해 데이터, 018.논문자료 요약 데이터, 019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터, 021.도서자료 기계독해, 022.요약문 및 레포트 생성 데이터, 023.방송 콘텐츠 대본 요약 데이터, 025.일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터, 026.기술과학 분야 한-영 번역 병렬 말뭉치 데이터, 027.일상생활 및 구어체 한-중, 한-일 번역 병렬 말뭉치 데이터, 028.다국어 구어체 번역 병렬 말뭉치 데이터, 029.대규모 구매도서 기반 한국어 말뭉치 데이터, 030.웹데이터 기반 한국어 말뭉치 데이터, 031.온라인 구어체 말뭉치 데이터, 032.방송콘텐츠 한국어-영어 번역 말뭉치, 034.방송콘텐츠 한국어-유럽어 번역 말뭉치, 036.방송콘텐츠 한국어-아시아어 번역 말뭉치, 044.페르소나 대화, 045.지식검색 대화, 046.공감형 대화, 048.일반상식 문장 생성 데이터, 053.한국어-다국어(영어 제외) 번역 말뭉치(기술과학), 054.한국어-다국어 번역 말뭉치(기초과학), 055.한국어-다국어 번역 말뭉치(인문학), 119.국가기록물 대상 초거대AI 학습을 위한 말뭉치 데이터, 121.한국어 성능이 개선된 초거대AI 언어모델 개발 및 데이터, 141.한국어 멀티세션 대화, 150.숫자연산 기계독해 데이터, 152.기술과학 문서 기계독해 데이터, 153.기술과학 요약 데이터, 155.산업정보 연계 주요국 특허 영-한 데이터, 156.전문분야 영-한, 중-한 번역 말뭉치(식품), 157.방송 콘텐츠 한-중, 한-일 번역 병렬 말뭉치 데이터, 157.추상 요약 사실성 검증 데이터, NIKLNEWSPAPER_2022_v1.0_JSON.zip, NIKL_DIALOGUE_2020_v1.4.zip, NIKL_DIALOGUE_2021_v1.1.zip, NIKL_DIALOGUE_2022_v1.0_JSON.zip, NIKL_NEWSPAPER_2020_v1.1_JSON.zip, NIKL_NEWSPAPER_2021_v1.0_JSON.zip, NIKL_NEWSPAPER_2023_JSON_v1.0.zip, NIKL_NEWSPAPER_v2.0_JSON.zip, NIKL_WRITTEN_v1.2_JSON.zip, 기계독해, 도서자료 요약, 문서요약 텍스트]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:13.256275Z",
     "start_time": "2024-11-24T07:12:13.119832Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// export file names as a markdown list then save it\n",
    "val markdownList = files.joinToString(\"\\n\") { \"- $it\" }\n",
    "File(\"datasets.md\").writeText(markdownList)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:13.413910300Z",
     "start_time": "2024-11-24T07:12:13.259435600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val scope = newFixedThreadPoolContext(\n",
    "//    Runtime.getRuntime().availableProcessors() / 2,\n",
    "    8,\n",
    "    \"preprocessor\"\n",
    ").let { CoroutineScope(it) }"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:14.484912500Z",
     "start_time": "2024-11-24T07:12:13.424625500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlinx.coroutines.*\n",
    "import kotlinx.coroutines.sync.Mutex\n",
    "import kotlinx.coroutines.sync.withLock\n",
    "import java.util.concurrent.ConcurrentHashMap\n",
    "import kotlin.random.Random\n",
    "import kotlin.time.Duration\n",
    "\n",
    "class ProgressBar(val max: Int, var taskName: String, val register: ProgressBarRegistry) {\n",
    "    val terminalWidth = 100\n",
    "    var current = 0\n",
    "    private val currentMutex = Mutex()\n",
    "\n",
    "    init {\n",
    "        register.register(this)\n",
    "    }\n",
    "\n",
    "    fun step(): Unit = runBlocking {\n",
    "        currentMutex.withLock {\n",
    "            current += 1\n",
    "        }\n",
    "\n",
    "        register.update()\n",
    "        if (current >= max) register.unregister(this@ProgressBar)\n",
    "    }\n",
    "\n",
    "    fun stepBy(step: Int): Unit = runBlocking {\n",
    "        currentMutex.withLock {\n",
    "            current += step.toInt()\n",
    "        }\n",
    "\n",
    "        register.update()\n",
    "        if (current >= max) register.unregister(this@ProgressBar)\n",
    "    }\n",
    "\n",
    "    fun close() {\n",
    "        register.unregister(this)\n",
    "    }\n",
    "    \n",
    "    fun render() = buildString {\n",
    "        val len = (current.toDouble() / max * terminalWidth).also { \n",
    "            if (it.isNaN()) return@buildString\n",
    "        }.roundToInt()\n",
    "        \n",
    "        if (len < 0 || len > terminalWidth) return@buildString\n",
    "        \n",
    "        append(taskName)\n",
    "        append(\"\\t[\")\n",
    "        append(\"■\".repeat(len))\n",
    "        append(\"□\".repeat(terminalWidth - len))\n",
    "        append(\"]\\t(${current}/${max} ${String.format(\"%.2f\", ((current) / max.toDouble()) * 100)}%)\")\n",
    "    }.trim() // .let { htmlResult(\"<span>${it}</span>\") }\n",
    "}\n",
    "\n",
    "class ProgressBarRegistry() {\n",
    "    private val progressBars = ConcurrentHashMap<ProgressBar, Int>()\n",
    "    private val random = Random(System.currentTimeMillis())\n",
    "\n",
    "    fun register(progressBar: ProgressBar) {\n",
    "        progressBars.set(progressBar, random.nextInt().absoluteValue)\n",
    "//        DISPLAY(progressBar.render().withId(progressBars[progressBar]!!.toString()), id=progressBars[progressBar]!!.toString())\n",
    "//        this.update()\n",
    "    }\n",
    "\n",
    "    fun unregister(progressBar: ProgressBar) {\n",
    "        progressBars.remove(progressBar)\n",
    "    }\n",
    "\n",
    "    fun update() {\n",
    "        progressBars.forEach { progressBar ->\n",
    "            // just print it\n",
    "            if (progressBar.key.max < 100) println(progressBar.key.render())\n",
    "            else {\n",
    "                val threshold = (progressBar.key.max.toDouble() / 10).let { \n",
    "                    if (it.isNaN()) -1.0 else it\n",
    "                }.roundToInt()\n",
    "\n",
    "                if (progressBar.key.current % threshold == 0) println(progressBar.key.render())\n",
    "            }\n",
    "//            UPDATE_DISPLAY(progressBar.key.render().withId(progressBars[progressBar.key]!!.toString()), id = progressBars[progressBar.key]!!.toString())\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "class ProgressBarIterable<T>(val list: List<T>, val taskName: String, val registry: ProgressBarRegistry): Iterable<T> {\n",
    "    private val progressBar = ProgressBar(list.count(), taskName, registry)\n",
    "    private val iter = list.iterator()\n",
    "    \n",
    "    override fun iterator(): Iterator<T> = object : Iterator<T> {\n",
    "        override fun hasNext(): Boolean = iter.hasNext()\n",
    "        override fun next(): T = iter.next().also { progressBar.step() }\n",
    "    }\n",
    "\n",
    "    fun close() {\n",
    "        progressBar.close()\n",
    "    }\n",
    "}\n",
    "\n",
    "val registry = ProgressBarRegistry()\n",
    "\n",
    "fun <T> List<T>.withProgressBar(taskName: String): Iterable<T> = ProgressBarIterable<T>(this, taskName, registry)"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:16.932398600Z",
     "start_time": "2024-11-24T07:12:14.493421700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import com.vladsch.flexmark.html2md.converter.FlexmarkHtmlConverter\n",
    "import org.apache.commons.compress.archivers.zip.ZipArchiveEntry\n",
    "import org.apache.commons.compress.archivers.zip.ZipFile\n",
    "import java.io.File\n",
    "import java.io.InputStream\n",
    "import java.util.zip.ZipEntry\n",
    "import kotlin.io.path.createTempDirectory\n",
    "import kotlin.io.path.outputStream\n",
    "\n",
    "// Let's process the first file, step by step\n",
    "\n",
    "// first, declare some utils\n",
    "\n",
    "interface Preprocessor {\n",
    "    val type: PreprocessorType\n",
    "    \n",
    "    fun read(file: File): DataFrame<*>\n",
    "    fun preprocess(data: DataFrame<*>): DataFrame<*>\n",
    "}\n",
    "\n",
    "abstract class PreprocessorWithoutPreprocessing: Preprocessor {\n",
    "    abstract override fun read(file: File): DataFrame<*>\n",
    "    \n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> {\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "enum class PreprocessorType {\n",
    "    CORPUS, CORPUS_SPOKEN, TASK_SUMMARIZATION, TASK_TRANSLATION,\n",
    "    CHAT, DIALECT\n",
    "}\n",
    "\n",
    "val converter = FlexmarkHtmlConverter.builder().apply { set(FlexmarkHtmlConverter.SETEXT_HEADINGS, false) }.build()\n",
    "val correctPunctuation = setOf('.', '!', '?', '\"', \"'\")\n",
    "val commonGrammarMistakes = mapOf(\n",
    "    \"몇일\" to \"며칠\",\n",
    "    \"는 커녕\" to \"는커녕\",\n",
    "    \"은 커녕\" to \"은커녕\",\n",
    "    \" 라고\" to \"라고\",\n",
    "    \" 부터\" to \"부터\",\n",
    "    \" 투성이\" to \"투성이\",\n",
    "    \" 짜리\" to \"짜리\",\n",
    "    \" 어치\" to \"어치\",\n",
    "    \"할려고\" to \"하려고\",\n",
    "    \"어떻해\" to \"어떡해\",\n",
    "    \"어짜피\" to \"어차피\",\n",
    "    \"곰곰히\" to \"곰곰이\",\n",
    "    \"요세\" to \"요새\",\n",
    "    \"금새\" to \"금세\",\n",
    "    \"왠\" to \"웬\",\n",
    "    \"웬지\" to \"왠지\",\n",
    "    \"오랫만에\" to \"오랜만에\",\n",
    "    \"일일히\" to \"일일이\",\n",
    "    \"희안하다\" to \"희한하다\",\n",
    "    \"희안한\" to \"희한한\",\n",
    "    \"희안하게\" to \"희한하게\",\n",
    "    \"않된\" to \"안 된\",\n",
    "    \"돼었\" to \"되었\",\n",
    "    \"돼고\" to \"되고\",\n",
    "    \"어의없\" to \"어이없\",\n",
    "    \"어의가 없\" to \"어이가 없\",\n",
    "    \"불리우다\" to \"불리다\",\n",
    "    \"불리우는\" to \"불리는\",\n",
    "    \"매일마다\" to \"매일\",\n",
    "    \"깨끗히\" to \"깨끗이\",\n",
    "    \"역활\" to \"역할\",\n",
    "    \"순조로와\" to \"순조로워\",\n",
    "    \"알맞는\" to \"알맞은\",\n",
    "    \"여지껏\" to \"여태껏\",\n",
    "    \"유도심문\" to \"유도신문\",\n",
    "    \"도데체\" to \"도대체\",\n",
    "    \"거에요\" to \"거예요\",\n",
    "    \"궂이\" to \"굳이\",\n",
    "    \"구지\" to \"굳이\",\n",
    "    \"것 뿐\" to \"것뿐\",\n",
    "    \"치루다\" to \"치르다\",\n",
    "    \"치뤘다\" to \"치렀다\",\n",
    "    \"치뤄\" to \"치러\",\n",
    ")\n",
    "\n",
    "val commonGrammarMistakesStatistics = commonGrammarMistakes.map { mistake -> mistake.key to (Mutex() to 0) }.toMap().toMutableMap()\n",
    "\n",
    "fun standardNormalizeText(text: String): String = runBlocking {\n",
    "    converter.convert(text.trim().replace(\"\\t\", \" \").replace(\"  \", \" \").replace(\"\\n\", \"<br>\")).replace(\"○\", \"-\").replace(\"❍\", \"-\").replace(\"  \", \" \").replace(\" \", \" \").replace(\"\\n\\n\", \"\\n\").replace(\"<br />\", \"\\n\").trim().let {\n",
    "        commonGrammarMistakes.entries.fold(it) { acc, mistake ->\n",
    "            acc.replace(mistake.key, mistake.value).also {\n",
    "                if (it != acc) commonGrammarMistakesStatistics[mistake.key]!!.first.withLock {\n",
    "                    commonGrammarMistakesStatistics[mistake.key] = commonGrammarMistakesStatistics[mistake.key]!!.first to commonGrammarMistakesStatistics[mistake.key]!!.second + 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "/**\n",
    " * @return true if the text is valid, otherwise false\n",
    " */\n",
    "fun standardVaildText(text: String, isSentence: Boolean = false): Boolean = text.trim().let {\n",
    "    if (it.isEmpty()) return false\n",
    "    if (it.length < 8) return false\n",
    "    \n",
    "    if (isSentence) {\n",
    "        if (it.last() !in correctPunctuation) return false\n",
    "        if (it.first() in correctPunctuation) return false\n",
    "    }\n",
    "    \n",
    "    true\n",
    "}\n",
    "\n",
    "fun String.addSuffixIfNotExists(suffix: String): String = if (this.endsWith(suffix)) this else this + suffix\n",
    "\n",
    "val directMapping = mapOf<String, File.() -> List<File>>(\n",
    "    \"기계독해\" to { listOf(this.resolve(\"기계독해분야\")) },\n",
    "    \"도서자료 요약\" to { listOf(this.resolve(\"Training\")) },\n",
    "    \"문서요약 텍스트\" to { listOf(this.resolve(\"Training\")) },\n",
    ")\n",
    "\n",
    "fun File.auto1(): File =  if (this.listFiles()!!.map { it.name }.contains(\"01.데이터\")) this.resolve(\"01.데이터\")\n",
    "                          else if (this.listFiles()!!.map { it.name }.contains(\"1.데이터\")) this.resolve(\"1.데이터\")\n",
    "                          else if (this.listFiles()!!.map { it.name }.contains(\"3.개방데이터\")) this.resolve(\"3.개방데이터\").auto1()\n",
    "                          else this.resolve(\"01-1.정식개방데이터\")\n",
    "\n",
    "fun File.auto2() = this.listFiles()!!.first { it.name.contains(\"Training\") }\n",
    "\n",
    "fun File.auto3(raw: Boolean) = if (raw) this.listFiles()!!.filter { it.name.contains(\"원천데이터\") } else this.listFiles()!!.filter { it.name.contains(\"라벨링데이터\") }\n",
    "\n",
    "fun File.auto(raw: Boolean = false) = this.let { \n",
    "    if (directMapping.containsKey(this.name)) directMapping[this.name]!!.invoke(this)\n",
    "    else this.auto1().auto2().auto3(raw)\n",
    "}.map { it.walk().toList() }.flatten().filter { it.extension == \"zip\" }\n",
    "\n",
    "fun List<File>.zipsJsonCount(): Int = this.map { zipPath ->\n",
    "    ZipFile.builder().setFile(zipPath).get().use { zipFile ->\n",
    "        zipFile.entries.toList().count() { entry -> entry.name.endsWith(\".json\") }\n",
    "    }\n",
    "}.sum()\n",
    "\n",
    "//fun <T: Any> List<File>.zipsJsonWalk(block: (zipPath: String, zipFile: String, stream: InputStream) -> T?): List<T> =\n",
    "//    ProgressBar(this.zipsJsonCount(), \"Zip Walk\", registry).let {\n",
    "//        this.flatMapIndexed { zipIdx, zipPath ->\n",
    "//            ZipFile.builder().setFile(zipPath).get().use { zipFile ->\n",
    "//                zipFile.entries.asSequence().filter { f -> f.name.endsWith(\".json\") }.mapIndexedNotNull() { idx, entry ->\n",
    "//                    zipFile.getInputStream(entry).use { inputStream ->\n",
    "//                        runCatching {\n",
    "//                            block(zipPath.toString(), entry.name, inputStream)\n",
    "//                        }.getOrNull()\n",
    "//                    }.apply {\n",
    "//                        it.taskName = \"Zip Walk(now ...${\n",
    "//                            String.format(\"%.20s\", zipPath.toString().reversed()).reversed()\n",
    "//                        } ${\n",
    "//                            String.format(\"%.20s\", entry.name.toString().reversed()).reversed()\n",
    "//                        })\"\n",
    "//                        it.step()\n",
    "//                    }\n",
    "//                }.toList()\n",
    "//            }\n",
    "//        }\n",
    "//    }\n",
    "\n",
    "fun <T: Any> List<File>.zipsJsonWalkNonAsync(block: (zipPath: String, zipFile: String, stream: InputStream) -> T?): List<T> =\n",
    "    ProgressBar(this.zipsJsonCount(), \"Zip Walk\", registry).let {\n",
    "        this.flatMapIndexed { zipIdx, zipPath ->\n",
    "            ZipFile.builder().setFile(zipPath).get().use { zipFile ->\n",
    "                zipFile.entries.asSequence().filter { f -> f.name.endsWith(\".json\") }\n",
    "                    .mapIndexed { idx, entry ->\n",
    "                        zipFile.getInputStream(entry).use { inputStream ->\n",
    "                            runCatching {\n",
    "                                block(zipPath.toString(), entry.name, inputStream)\n",
    "                            }.onFailure { \n",
    "                                it.printStackTrace()\n",
    "                            }.getOrNull()\n",
    "                        }.apply {\n",
    "                            it.taskName = \"Zip Walk(now ...${\n",
    "                                String.format(\"%.20s\", zipPath.toString().reversed()).reversed()\n",
    "                            } ${\n",
    "                                String.format(\"%.20s\", entry.name.toString().reversed()).reversed()\n",
    "                            })\"\n",
    "                            it.step()\n",
    "                        }\n",
    "                    }.toList().filterNotNull()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "fun <T: Any> List<File>.zipsJsonWalk(lessMemory: Boolean = false, block: (zipPath: String, zipFile: String, stream: InputStream) -> T?): List<T> =\n",
    "    if (lessMemory) this.zipsJsonWalkAsyncLessMem(block)\n",
    "    else this.zipsJsonWalkAsync(block)\n",
    "\n",
    "fun <T: Any> List<File>.zipsJsonWalkAsync(block: (zipPath: String, zipFile: String, stream: InputStream) -> T?): List<T> = runBlocking {\n",
    "    ProgressBar(this@zipsJsonWalkAsync.zipsJsonCount(), \"Zip Walk\", registry).let {\n",
    "        this@zipsJsonWalkAsync.flatMapIndexed { zipIdx, zipPath ->\n",
    "            ZipFile.builder().setFile(zipPath).get().use { zipFile ->\n",
    "                zipFile.entries.asSequence().filter { f -> f.name.endsWith(\".json\") }\n",
    "                    .mapIndexed { idx, entry ->\n",
    "                        scope.async {\n",
    "                            zipFile.getInputStream(entry).use { inputStream ->\n",
    "                                runCatching {\n",
    "                                    block(zipPath.toString(), entry.name, inputStream)\n",
    "                                }.getOrNull()\n",
    "                            }.apply {\n",
    "                                it.taskName = \"Zip Walk(now ...${\n",
    "                                    String.format(\"%.20s\", zipPath.toString().reversed()).reversed()\n",
    "                                } ${\n",
    "                                    String.format(\"%.20s\", entry.name.toString().reversed()).reversed()\n",
    "                                })\"\n",
    "                                it.step()\n",
    "                            }\n",
    "                        }\n",
    "                    }.toList().awaitAll().filterNotNull()\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "fun <T: Any> List<File>.zipsJsonWalkAsyncLessMem(block: (zipPath: String, zipFile: String, stream: InputStream) -> T?): List<T> = runBlocking {\n",
    "    // first, decompress all files\n",
    "    val tempDir = createTempDirectory()\n",
    "    \n",
    "    ProgressBar(this@zipsJsonWalkAsyncLessMem.zipsJsonCount(), \"Zip Decompress\", registry).let {\n",
    "        this@zipsJsonWalkAsyncLessMem.map { zipPath ->\n",
    "            scope.async {\n",
    "                ZipFile.builder().setFile(zipPath).get().use { zipFile ->\n",
    "                    zipFile.entries.asSequence().filter { f -> f.name.endsWith(\".json\") }.forEach { entry ->\n",
    "                        zipFile.getInputStream(entry).use { inputStream ->\n",
    "                            val file = tempDir.resolve(entry.rawName.let {\n",
    "                                // try utf-8 , if it fails, then use cp949\n",
    "                                runCatching { String(it, Charsets.UTF_8) }.getOrNull() ?: String(\n",
    "                                    it,\n",
    "                                    Charsets.ISO_8859_1\n",
    "                                )\n",
    "                            })\n",
    "                            file.outputStream().use { inputStream.copyTo(it) }.apply { it.step() }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }.awaitAll()\n",
    "    }\n",
    "    \n",
    "    // second, process\n",
    "    \n",
    "    ProgressBar(tempDir.toFile().listFiles()!!.count(), \"Zip Walk\", registry).let {\n",
    "        tempDir.toFile().listFiles()!!.toList().map{ file ->\n",
    "            scope.async {\n",
    "                file.inputStream().use { inputStream ->\n",
    "                    runCatching {\n",
    "                        block(file.absolutePath, file.name, inputStream)\n",
    "                    }.getOrNull()\n",
    "                }.apply {\n",
    "                    it.step()\n",
    "                }\n",
    "            }\n",
    "        }.awaitAll().filterNotNull()\n",
    "    }\n",
    "    \n",
    "    listOf()\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:17.163323400Z",
     "start_time": "2024-11-24T07:12:16.941473500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlinx.serialization.Serializable\n",
    "\n",
    "@Serializable\n",
    "data class ChatRow(val role: String, val content: String)"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:17.354487800Z",
     "start_time": "2024-11-24T07:12:17.179341500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlin.time.measureTime\n",
    "import kotlin.time.measureTimedValue\n",
    "\n",
    "class FastPreprocessor(val preprocessor: Preprocessor, var batchSize: Int = 10000): Preprocessor by preprocessor {\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> = runBlocking {\n",
    "        if (preprocessor is PreprocessorWithoutPreprocessing) return@runBlocking data\n",
    "        \n",
    "//        measureTimedValue {\n",
    "        val batches = data.chunked(batchSize).toList()\n",
    "        val progress = ProgressBar(data.rowsCount(), \"Batch processing\", registry)\n",
    "        val processed = \n",
    "            batches.map { batch -> scope.async { preprocessor.preprocess(batch).apply { \n",
    "                progress.stepBy(batchSize)\n",
    "            } } }.awaitAll()\n",
    "        \n",
    "        processed.reduce { acc, df -> acc.concat(df) }\n",
    "//        }.also { println(\"Time elapsed: ${it.duration.inWholeMilliseconds}ms\") }.value\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:17.659014100Z",
     "start_time": "2024-11-24T07:12:17.360002300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val preprocessors = mutableMapOf<String, MutableMap<PreprocessorType, Preprocessor>>()\n",
    "\n",
    "fun declarePreprocessor(preprocessor: Preprocessor, forFiles: List<String>, showDatabase: Boolean = false, showExamples: Boolean = false, showInfo: Boolean = true, fast: Boolean = true) {\n",
    "    val fastProcessor = if (fast) FastPreprocessor(preprocessor) else preprocessor\n",
    "\n",
    "    forFiles.forEach { preprocessors[it].let { map ->\n",
    "        if (map == null) preprocessors[it] = mutableMapOf(preprocessor.type to fastProcessor)\n",
    "        else map[preprocessor.type] = fastProcessor\n",
    "    } }\n",
    "\n",
    "    if (onlyExport) return\n",
    "\n",
    "    val data = forFiles.map { fastProcessor.read(File(\"./datasets/${it}\")) }.reduce { acc, df -> acc.concat(df) }\n",
    "        .also { println(\"Count of rows: ${it.rowsCount()}\") }\n",
    "\n",
    "    if (showDatabase) DISPLAY(data.head(100))\n",
    "\n",
    "    val result = fastProcessor.preprocess(data)\n",
    "\n",
    "    if (showExamples) {\n",
    "        DISPLAY(result.shuffle().head(100).let {\n",
    "            if (showInfo) DataFrame.readJsonStr(\n",
    "                buildJsonObject {\n",
    "                    put(when(preprocessor.type) {\n",
    "                        PreprocessorType.CHAT -> \"chat\"\n",
    "                        else -> \"text\"\n",
    "                    }, buildJsonObject {\n",
    "                            put(\"before_row_count\", data.rowsCount())\n",
    "                            put(\"after_row_count\", result.rowsCount())\n",
    "                            put(\"preprocessor\", preprocessor::class.simpleName)\n",
    "                            put(\"preprocessor_type\", preprocessor.type.name)\n",
    "                        })\n",
    "                }.toString()\n",
    "            ).concat(it) else it\n",
    "        })\n",
    "    }\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:17.732812200Z",
     "start_time": "2024-11-24T07:12:17.664013800Z"
    }
   },
   "cell_type": "code",
   "source": "fun DataFrame<*>.filterColumns(vararg columnsToKeep: String): DataFrame<*> = this.remove(*(this.columnNames() - columnsToKeep).toTypedArray())",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:17.854274400Z",
     "start_time": "2024-11-24T07:12:17.736813100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun List<ChatRow>.mergeRepeating(): List<ChatRow> {\n",
    "    if (this.isEmpty()) return emptyList()\n",
    "\n",
    "    val merged = mutableListOf<ChatRow>()\n",
    "    var lastSpeaker = this.first().role\n",
    "    var lastText = this.first().content\n",
    "\n",
    "    for ((speaker, text) in this.drop(1)) {\n",
    "        if (speaker == lastSpeaker) {\n",
    "            lastText += \" $text\"\n",
    "        } else {\n",
    "            merged.add(ChatRow(lastSpeaker, lastText))\n",
    "            lastSpeaker = speaker\n",
    "            lastText = text\n",
    "        }\n",
    "    }\n",
    "    merged.add(ChatRow(lastSpeaker, lastText))\n",
    "\n",
    "    return merged\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:18.015101Z",
     "start_time": "2024-11-24T07:12:17.858274300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForMachineReading : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"paragraphs\"<DataFrame<*>>().first()[\"context\"].let { standardNormalizeText(it as String) } }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"data\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForMachineReading(),\n",
    "    listOf(\"016.행정 문서 대상 기계독해 데이터\", \"017.뉴스 기사 기계독해 데이터\", \"021.도서자료 기계독해\", \"기계독해\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:18.133225800Z",
     "start_time": "2024-11-24T07:12:18.020190100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForMachineReadingMath : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"## ${\"title\"<String>()}\\n ${\"passage\"<String>()}\".let { standardNormalizeText(it) } }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"data\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForMachineReadingMath(),\n",
    "    listOf(\"150.숫자연산 기계독해 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:18.259752700Z",
     "start_time": "2024-11-24T07:12:18.139569300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForMachineReadingTech : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"context\"<String>().let { standardNormalizeText(it) } }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"dataset\"][\"context_info\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForMachineReadingTech(),\n",
    "    listOf(\"152.기술과학 문서 기계독해 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:18.303353500Z",
     "start_time": "2024-11-24T07:12:18.264753300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val translateInstructions = listOf(\n",
    "    \"{a}로 쓰인 내용을 {b}로 번역해 주세요.\",\n",
    "    \"{a}에서 {b}로 번역해 주세요.\",\n",
    "    \"{a}로 작성된 문장을 {b}로 적어 주세요.\",\n",
    "    \"{a} 글을 {b} 언어로 자연스럽게 번역해 주세요.\",\n",
    "    \"{a}로 쓰인 글을 {b}로 옮겨 주세요.\",\n",
    "    \"{a}로 된 글을 {b}로 바꿔 보세요.\",\n",
    "    \"{a}에서 {b}로 자연스럽게 번역해 주세요.\",\n",
    "    \"{a} 내용을 {b}로 다시 써 주세요.\",\n",
    "    \"{a} 문장을 {b}로 자연스럽게 바꿔 주세요.\",\n",
    "    \"{a} 내용을 {b}로 매끄럽게 번역해 주세요.\",\n",
    "    \"{a}를 {b}로 해석해 주세요.\",\n",
    "    \"이 글을 {b}로 번역해 주세요.\",\n",
    "    \"{b}로 옮겨 쓰세요.\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:18.522011300Z",
     "start_time": "2024-11-24T07:12:18.307353500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForParrellLanguageTypeA : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_TRANSLATION\n",
    "\n",
    "    private val languageTable = mapOf(\n",
    "        \"en\" to \"영어\",\n",
    "        \"ko\" to \"한국어\",\n",
    "        \"cn\" to \"중국어\",\n",
    "        \"jp\" to \"일본어\",\n",
    "    )\n",
    "\n",
    "    private fun form(index: Int, style: String, sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", translateInstructions[index % translateInstructions.size].replace(\"{a}\", sourceLanguage).replace(\"{b}\", targetLanguage) + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", targetText))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .add(\"from\") { languageTable[\"source_language\"<String>()]!! }.also { println(\"from\") }\n",
    "            .add(\"to\") { languageTable[\"target_language\"<String>()]!! }.also { println(\"to\") }\n",
    "            .filter { standardVaildText(\"${\"source_language\"<String>()}\"<String>()) && standardVaildText(\"${\"target_language\"<String>()}\"<String>()) }.also { println(\"filter\") }\n",
    "//            .explode(\"from\")\n",
    "//            .explode(\"to\")\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(), style = \"style\"<String>(), sourceLanguage =\"from\"<String>(), targetLanguage = \"to\"<String>(), sourceText = (\"${\"source_language\"<String>()}\"<String>()).let {\n",
    "                    standardNormalizeText(it)\n",
    "                }, targetText = (\"${\"target_language\"<String>()}\"<String>()).let {\n",
    "                    standardNormalizeText(it)\n",
    "                })\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"data\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "//PreprocessorForParrellLanguage().read(File(\"./datasets/025.일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터\"))\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellLanguageTypeA(),\n",
    "    listOf(\"025.일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터\", \"026.기술과학 분야 한-영 번역 병렬 말뭉치 데이터\", \"156.전문분야 영-한, 중-한 번역 말뭉치(식품)\", \"157.방송 콘텐츠 한-중, 한-일 번역 병렬 말뭉치 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:18.810107700Z",
     "start_time": "2024-11-24T07:12:18.526526700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForParrellLanguageTypeB : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_TRANSLATION\n",
    "\n",
    "    private val languageTable = mapOf(\n",
    "        \"en-US\" to \"영어\",\n",
    "        \"ko-KR\" to \"한국어\",\n",
    "        \"fr-FR\" to \"프랑스어\",\n",
    "        \"zh-CN\" to \"중국어\",\n",
    "        \"ja-JP\" to \"일본어\",\n",
    "        \"de-DE\" to \"독일어\",\n",
    "        \"es-ES\" to \"스페인어\",\n",
    "        \"it-IT\" to \"이탈리아어\"\n",
    "    )\n",
    "\n",
    "    private fun form(index: Int, sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", translateInstructions[index % translateInstructions.size].replace(\"{a}\", sourceLanguage).replace(\"{b}\", \"구어체의 ${targetLanguage}\") + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", targetText))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter {\n",
    "                this[\"S_Code\"] in languageTable.keys && this[\"T_Code\"] in languageTable.keys && this[\"원문\"] is String && this[\"최종번역문\"] is String\n",
    "            }\n",
    "            .filter { standardVaildText(\"원문\"<String>()) && standardVaildText(\"최종번역문\"<String>()) }\n",
    "            .add(\"from\") { \"S_Code\"<String>().let { languageTable[it]!! } }\n",
    "            .add(\"to\") { \"T_Code\"<String>().let { languageTable[it]!!} }\n",
    "//            .explode(\"from\")\n",
    "//            .explode(\"to\")\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    sourceLanguage = \"from\"<String>(),\n",
    "                    targetLanguage = \"to\"<String>(),\n",
    "                    sourceText = (\"원문\"<String>()).let { standardNormalizeText(it) },\n",
    "                    targetText = (\"최종번역문\"<String>()).let { standardNormalizeText(it) }\n",
    "                )\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            try {\n",
    "                val dataFrame = DataFrame.readJson(stream)\n",
    "                dataFrame\n",
    "            } catch (e: Exception) {\n",
    "                null\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "//PreprocessorForParrellLanguageTypeB().read(File(\"./datasets/028.다국어 구어체 번역 병렬 말뭉치 데이터\")).let {\n",
    "//    // print all languages\n",
    "//    it[\"S_Code\"].distinct().forEach { println(it) }\n",
    "//    it[\"T_Code\"].distinct().forEach { println(it) }\n",
    "//}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellLanguageTypeB(),\n",
    "    listOf(\"027.일상생활 및 구어체 한-중, 한-일 번역 병렬 말뭉치 데이터\", \"028.다국어 구어체 번역 병렬 말뭉치 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:19.206312900Z",
     "start_time": "2024-11-24T07:12:18.818114800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForParrellLanguageTypeC : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_TRANSLATION\n",
    "\n",
    "    private val languageTable = mapOf(\n",
    "        \"en-US\" to \"영어\",\n",
    "        \"ko-KR\" to \"한국어\",\n",
    "        \"fr-FR\" to \"프랑스어\",\n",
    "        \"zh-CN\" to \"중국어\",\n",
    "        \"ja-JP\" to \"일본어\",\n",
    "        \"de-DE\" to \"독일어\",\n",
    "        \"es-ES\" to \"스페인어\",\n",
    "        \"it-IT\" to \"이탈리아어\",\n",
    "        \"ru-RU\" to \"러시아어\",\n",
    "    )\n",
    "\n",
    "    private fun form(index: Int, sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", translateInstructions[index % translateInstructions.size].replace(\"{a}\", sourceLanguage).replace(\"{b}\", targetLanguage) + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", targetText))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "//            .filter {\n",
    "//                \"S_Code\" in this.columnNames() && \"T_Code\" in this.columnNames() && \"원문\" in this.columnNames() && \"최종번역문\" in this.columnNames()\n",
    "//            }\n",
    "//            .filter {\n",
    "//                this[\"S-Code\"] in languageTable.keys && this[\"T-Code\"] in languageTable.keys && this[\"원문\"] is String && this[\"최종번역문\"] is String\n",
    "//            }\n",
    "            .filter { standardVaildText(\"원문\"<String>()) && standardVaildText(\"최종번역문\"<String>()) }\n",
    "            .add(\"from\") { \"S-Code\"<String>().let { languageTable[it]!! } }\n",
    "            .add(\"to\") { \"T-Code\"<String>().let { languageTable[it]!!} }\n",
    "//            .explode(\"from\")\n",
    "//            .explode(\"to\")\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    sourceLanguage = \"from\"<String>(),\n",
    "                    targetLanguage = \"to\"<String>(),\n",
    "                    sourceText = (\"원문\"<String>()).let { standardNormalizeText(it) },\n",
    "                    targetText = (\"최종번역문\"<String>()).let { standardNormalizeText(it) }\n",
    "                )\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        var bigText = kotlin.io.path.createTempFile()\n",
    "\n",
    "        println(\"Merging all json files... temporary file: ${bigText.toFile().absolutePath}\")\n",
    "\n",
    "        val writer = bigText.toFile().bufferedWriter()\n",
    "\n",
    "        writer.write(\"[\")\n",
    "\n",
    "        file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            // json files are too many, so it should be merged as a single json array\n",
    "            writer.write(stream.bufferedReader().readText().also {\n",
    "                // if any line which \" is included more than 4 times, then it should be removed\n",
    "                // so throw an exception\n",
    "                if (it.lines().any { it.count { c -> c == '\"' } > 4 }) throw Exception(\"Too many quotes\")\n",
    "            } + \",\")\n",
    "        }\n",
    "\n",
    "        writer.write(\"{}\") // to remove the last comma\n",
    "\n",
    "        writer.write(\"]\")\n",
    "        writer.close()\n",
    "\n",
    "        val dataFrame = DataFrame.readJson(bigText.toFile()).let {\n",
    "            // skip last dummy\n",
    "            it[0..(it.rowsCount() - 2)]\n",
    "        }\n",
    "\n",
    "        return dataFrame\n",
    "    }\n",
    "}\n",
    "\n",
    "//PreprocessorForParrellLanguageTypeB().read(File(\"./datasets/028.다국어 구어체 번역 병렬 말뭉치 데이터\")).let {\n",
    "//    // print all languages\n",
    "//    it[\"S_Code\"].distinct().forEach { println(it) }\n",
    "//    it[\"T_Code\"].distinct().forEach { println(it) }\n",
    "//}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellLanguageTypeC(),\n",
    "    listOf(\"032.방송콘텐츠 한국어-영어 번역 말뭉치\", \"034.방송콘텐츠 한국어-유럽어 번역 말뭉치\"),\n",
    "    showDatabase = false,\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:19.397089Z",
     "start_time": "2024-11-24T07:12:19.212334600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForParrellLanguageTypeD : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_TRANSLATION\n",
    "\n",
    "    private fun form(index: Int, sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", translateInstructions[index % translateInstructions.size].replace(\"{a}\", sourceLanguage).replace(\"{b}\", targetLanguage) + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", targetText))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "            dataFrame.concat()\n",
    "                .filter { standardVaildText(\"07_text\"<DataRow<*>>()[\"1_text\"] as String) && standardVaildText(\"08_translation\"<DataRow<*>>()[\"1_text\"] as String) }\n",
    "                .add(\"messages\") {\n",
    "                    form(\n",
    "                        index = index(),\n",
    "                        sourceLanguage = \"02_srcinfo\"<DataRow<*>>()[\"3_language\"] as String,\n",
    "                        targetLanguage = \"08_translation\"<DataRow<*>>()[\"2_language\"] as String,\n",
    "                        sourceText = (\"07_text\"<DataRow<*>>()[\"1_text\"] as String).let { standardNormalizeText(it) },\n",
    "                        targetText = (\"08_translation\"<DataRow<*>>()[\"1_text\"] as String).let { standardNormalizeText(it) }\n",
    "                    )\n",
    "                }\n",
    "                .filterColumns(\"messages\")\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "//PreprocessorForParrellLanguageTypeB().read(File(\"./datasets/028.다국어 구어체 번역 병렬 말뭉치 데이터\")).let {\n",
    "//    // print all languages\n",
    "//    it[\"S_Code\"].distinct().forEach { println(it) }\n",
    "//    it[\"T_Code\"].distinct().forEach { println(it) }\n",
    "//}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellLanguageTypeD(),\n",
    "    listOf(\"036.방송콘텐츠 한국어-아시아어 번역 말뭉치\"),\n",
    "    showDatabase = false,\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:19.630387800Z",
     "start_time": "2024-11-24T07:12:19.418150400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForParrellLanguageTypeE : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_TRANSLATION\n",
    "\n",
    "    private val languageTable = mapOf(\n",
    "        \"en\" to \"영어\",\n",
    "        \"ko\" to \"한국어\",\n",
    "        \"ch\" to \"중국어\",\n",
    "        \"jp\" to \"일본어\",\n",
    "    )\n",
    "\n",
    "    private fun form(index: Int, sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", translateInstructions[index % translateInstructions.size].replace(\"{a}\", sourceLanguage).replace(\"{b}\", \"전문적인 ${targetLanguage}\") + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", targetText))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .add(\"from\") { \"src_lang\"<String>().let { languageTable[it]!! } }\n",
    "            .add(\"to\") { \"tgt_lang\"<String>().let { languageTable[it]!!} }\n",
    "            .filter { standardVaildText(\"src_sentence\"<String>()) && standardVaildText(\"tgt_sentence\"<String>()) }\n",
    "//            .explode(\"from\")\n",
    "//            .explode(\"to\")\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    sourceLanguage = \"from\"<String>(),\n",
    "                    targetLanguage = \"to\"<String>(),\n",
    "                    sourceText = (\"src_sentence\"<String>()).let { standardNormalizeText(it) },\n",
    "                    targetText = (\"tgt_sentence\"<String>()).let { standardNormalizeText(it) }\n",
    "                )\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"paragraph\"].asFrameColumn().concat()\n",
    "            dataFrame.let { it.remove(\"info\") }.explode(\"sentences\").flatten(\"sentences\")\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellLanguageTypeE(),\n",
    "    listOf(\"053.한국어-다국어(영어 제외) 번역 말뭉치(기술과학)\", \"054.한국어-다국어 번역 말뭉치(기초과학)\", \"055.한국어-다국어 번역 말뭉치(인문학)\"),\n",
    "    showDatabase = false,\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:19.936490500Z",
     "start_time": "2024-11-24T07:12:19.651419300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForParrellLanguageTypeF : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_TRANSLATION\n",
    "\n",
    "    private val languageTable = mapOf(\n",
    "        \"en\" to \"영어\",\n",
    "        \"ko\" to \"한국어\",\n",
    "        \"ch\" to \"중국어\",\n",
    "        \"jp\" to \"일본어\",\n",
    "    )\n",
    "\n",
    "    private fun form(index: Int, sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", translateInstructions[index % translateInstructions.size].replace(\"{a}\", sourceLanguage).replace(\"{b}\", \"전문적인 ${targetLanguage}\") + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", targetText))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .add(\"from\") { \"영어\" }\n",
    "            .add(\"to\") { \"한국어\" }\n",
    "            .add(\"from_text\") {\n",
    "                \"\"\"\n",
    "                | ## ${\"invention_title_eng\"<String>()}\n",
    "                | ### Abstract\n",
    "                | ${\"astrt_cont_eng\"<String>()}\n",
    "                |\n",
    "                | ### Description\n",
    "                | ${\"claim_eng\"<String>()}\n",
    "                \"\"\".trimMargin().trim()\n",
    "            }\n",
    "            .add(\"to_text\") {\n",
    "                \"\"\"\n",
    "                | ## ${\"invention_title_kor\"<String>()}\n",
    "                | ### 초록\n",
    "                | ${\"astrt_cont_kor\"<String>()}\n",
    "                |\n",
    "                | ### 설명\n",
    "                | ${\"claim_kor\"<String>()}\n",
    "                \"\"\".trimMargin().trim()\n",
    "            }\n",
    "            .filter { standardVaildText(\"from_text\"<String>()) && standardVaildText(\"to_text\"<String>()) }\n",
    "//            .explode(\"from\")\n",
    "//            .explode(\"to\")\n",
    "            .let {\n",
    "                // add reverse-pair\n",
    "                it.mapToFrame {\n",
    "                    \"from\" from it[\"to\"]\n",
    "                    \"to\" from it[\"from\"]\n",
    "                    \"from_text\" from it[\"to_text\"]\n",
    "                    \"to_text\" from it[\"from_text\"]\n",
    "                }\n",
    "            }\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    sourceLanguage = \"from\"<String>(),\n",
    "                    targetLanguage = \"to\"<String>(),\n",
    "                    sourceText = (\"from_text\"<String>()).let { standardNormalizeText(it) },\n",
    "                    targetText = (\"to_text\"<String>()).let { standardNormalizeText(it) }\n",
    "                )\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first()[\"labeled_data\"] as DataFrame<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellLanguageTypeF(),\n",
    "    listOf(\"155.산업정보 연계 주요국 특허 영-한 데이터\"),\n",
    "    showDatabase = false,\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.101144600Z",
     "start_time": "2024-11-24T07:12:19.944006500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForBookCorpus : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, zipFile, stream ->\n",
    "            if (zipFile.contains(\"INFO\")) return@zipsJsonWalkAsync null\n",
    "\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"paragraphs\"]\n",
    "            dataFrame.asFrameColumn().concat().let {\n",
    "                it\n",
    "                    .filter {\n",
    "                        // if any sentence is not valid, then it should be removed\n",
    "                        (\"sentences\"<DataFrame<*>>()).map { \"text\"<String>().trim() }.all { standardVaildText(it, true) }\n",
    "                    }\n",
    "                    .add(\"text\") { (\"sentences\"<DataFrame<*>>()).map { \"text\"<String>().trim() }.joinToString(\" \") .let { standardNormalizeText(it) } }\n",
    "                    .filterColumns(\"text\")\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForBookCorpus(),\n",
    "    listOf(\"029.대규모 구매도서 기반 한국어 말뭉치 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.260325200Z",
     "start_time": "2024-11-24T07:12:20.111659100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForNationalData : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"corpus\"<String>().replace(Regex(\"\"\"<\\|start\\|>[^<]*<\\|end\\|>\"\"\"), \"\").let { standardNormalizeText(it) } }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto(raw=true).filterNot { it.name.contains(\"TS_2\") }.zipsJsonWalkAsync { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJsonStr(stream.bufferedReader().readText().trim('﻿'))[\"data\"]\n",
    "\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForNationalData(),\n",
    "    listOf(\"119.국가기록물 대상 초거대AI 학습을 위한 말뭉치 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.381034600Z",
     "start_time": "2024-11-24T07:12:20.264323900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForLLMData : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { runCatching { \"contents\"<String>().replace(\"<NAME>\", \"\").replace(\"NAME\", \"\").let { standardNormalizeText(it) } }.getOrDefault(\"\") }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto(raw=true).zipsJsonWalkAsync { _, zipFile, stream ->\n",
    "            if (zipFile.contains(\"TS_02\")) return@zipsJsonWalkAsync null // rlhf data\n",
    "\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"data_info\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForLLMData(),\n",
    "    listOf(\"121.한국어 성능이 개선된 초거대AI 언어모델 개발 및 데이터\"),\n",
    "    showExamples = true,\n",
    "    showDatabase = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.418099800Z",
     "start_time": "2024-11-24T07:12:20.386036400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val summarizationInstructions = listOf(\n",
    "    \"주어진 글을 간결하게 요약해 주세요.\",\n",
    "    \"이 글의 핵심을 간단히 정리해 주세요.\",\n",
    "    \"이 글의 내용을 짧고 명료하게 요약하세요.\",\n",
    "    \"글의 핵심을 요약하세요.\",\n",
    "    \"글의 핵심 내용을 정리해 주세요.\",\n",
    "    \"이 글을 간단하게 요약해 주세요.\",\n",
    "    \"글의 주요 내용을 간단히 정리해 주세요.\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.565697700Z",
     "start_time": "2024-11-24T07:12:20.421104800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForPaperSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "    \n",
    "    private fun form(index: Int, sourceText: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "    \n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"summary\") { listOf(\n",
    "            it[\"summary_entire\"], it[\"summary_section\"]\n",
    "        ) }\n",
    "            .explode(\"summary\")\n",
    "            .explode(\"summary\")\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    (\"summary\"<DataRow<*>>()[\"orginal_text\"] as String).let { standardNormalizeText(it) },\n",
    "                    (\"summary\"<DataRow<*>>()[\"summary_text\"] as String).let { standardNormalizeText(it) }\n",
    "                )\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"data\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForPaperSummarization(),\n",
    "    listOf(\"018.논문자료 요약 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.709489600Z",
     "start_time": "2024-11-24T07:12:20.575208200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForPaperSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"summary\") { listOf(\n",
    "            it[\"summary_entire\"], it[\"summary_section\"]\n",
    "        ) }\n",
    "            .explode(\"summary\")\n",
    "            .explode(\"summary\")\n",
    "            .filter { standardVaildText(\"summary\"<DataRow<*>>()[\"orginal_text\"] as String) }\n",
    "            .add(\"text\") { (\"summary\"<DataRow<*>>()[\"orginal_text\"] as String).let { standardNormalizeText(it) } }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"data\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForPaperSummarizationAsCorpus(),\n",
    "    listOf(\"018.논문자료 요약 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:20.900443100Z",
     "start_time": "2024-11-24T07:12:20.715496200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForBroadcastSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "    \n",
    "    private fun form(index: Int, passage: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + passage))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter {\n",
    "                (\"Meta\"<DataRow<*>>()[\"passage\"] as String).let { standardVaildText(it) }\n",
    "            }\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    (\"Meta\"<DataRow<*>>()[\"passage\"] as String),\n",
    "                    (\"Annotation\"<DataRow<*>>()).let { \n",
    "                        \"${it[\"Summary1\"]} ${it[\"Summary2\"]} ${it[\"Summary3\"]}\".trim().let { standardNormalizeText(it) }\n",
    "                    }) \n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForBroadcastSummarization(),\n",
    "    listOf(\"023.방송 콘텐츠 대본 요약 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.006934600Z",
     "start_time": "2024-11-24T07:12:20.908948100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForBroadcastSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "    \n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter { (\"Meta\"<DataRow<*>>()[\"passage\"] as String).let { standardVaildText(it) } }\n",
    "            .add(\"text\") { (\"Meta\"<DataRow<*>>()[\"passage\"] as String).let { standardNormalizeText(it) } }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForBroadcastSummarizationAsCorpus(),\n",
    "    listOf(\"023.방송 콘텐츠 대본 요약 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.151671600Z",
     "start_time": "2024-11-24T07:12:21.011454800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForReportSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "    \n",
    "    private fun form(index: Int, passage: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + passage))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter {\n",
    "                (\"Meta(Refine)\"<DataRow<*>>()[\"passage\"] as String).let { standardVaildText(it) }\n",
    "            }\n",
    "            .add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    (\"Meta(Refine)\"<DataRow<*>>()[\"passage\"] as String).let {\n",
    "                    standardNormalizeText(it.replace(\"\\n   \", \"<br>\").replace(\"\\n  \", \" \").replace(\"<br>\", \"\\n \")).trim()\n",
    "                }, \"Annotation\"<DataRow<*>>().let {\n",
    "                    \"${it[\"summary1\"]} ${it[\"summary2\"]} ${it[\"summary3\"]}\".trim().let { standardNormalizeText(it) }\n",
    "                }) \n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForReportSummarization(),\n",
    "    listOf(\"022.요약문 및 레포트 생성 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.267355400Z",
     "start_time": "2024-11-24T07:12:21.166186400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForReportSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "    \n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter { (\"Meta(Refine)\"<DataRow<*>>()[\"passage\"] as String).let { standardVaildText(it) } }\n",
    "            .add(\"text\") { (\"Meta(Refine)\"<DataRow<*>>()[\"passage\"] as String).let { standardNormalizeText(it.replace(\"\\n   \", \"<br>\").replace(\"\\n  \", \" \").replace(\"<br>\", \"\\n \")).trim() } }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForReportSummarizationAsCorpus(),\n",
    "    listOf(\"022.요약문 및 레포트 생성 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.391473200Z",
     "start_time": "2024-11-24T07:12:21.271876200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForTechSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "    \n",
    "    private fun form(index: Int, context: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + context))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter { standardVaildText(\"context\"<String>()) }\n",
    "            .add(\"messages\") { form(index(), \"context\"<String>().let { standardNormalizeText(it) }, \"summary\"<String>().let { standardNormalizeText(it) }) }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"dataset\"][\"context_info\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForTechSummarization(),\n",
    "    listOf(\"153.기술과학 요약 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.480345400Z",
     "start_time": "2024-11-24T07:12:21.395474600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForTechSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"context\"<String>().let { standardNormalizeText(it) } }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"dataset\"][\"context_info\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForTechSummarizationAsCorpus(),\n",
    "    listOf(\"153.기술과학 요약 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.614295600Z",
     "start_time": "2024-11-24T07:12:21.484345200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForAbstractSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "\n",
    "    private fun form(index: Int, sourceText: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter { standardVaildText(\"original_text\"<String>()) }\n",
    "            .add(\"messages\") { form(index(), \"original_text\"<String>().let { standardNormalizeText(it) }, ((\"annotation\"<DataRow<*>>()[\"original_summary\"] as DataRow<*>)[\"human_abstractive_summary\"] as DataRow<*>).let { standardNormalizeText(it[\"text\"] as String) }) }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForAbstractSummarization(),\n",
    "    listOf(\"157.추상 요약 사실성 검증 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.710722400Z",
     "start_time": "2024-11-24T07:12:21.619804600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForAbstractSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"original_text\"<String>().let { standardNormalizeText(it) } }\n",
    "            .filter { standardVaildText(\"text\"<String>()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForAbstractSummarizationAsCorpus(),\n",
    "    listOf(\"157.추상 요약 사실성 검증 데이터\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.809432800Z",
     "start_time": "2024-11-24T07:12:21.715720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForBookSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "\n",
    "    private fun form(index: Int, passage: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + passage))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"messages\") {\n",
    "                form(\n",
    "                    index=index(),\n",
    "                    \"passage\"<String>().let { standardNormalizeText(it) },\n",
    "                    \"summary\"<String>().let { standardNormalizeText(it) }\n",
    "                )\n",
    "            }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForBookSummarization(),\n",
    "    listOf(\"도서자료 요약\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.874428900Z",
     "start_time": "2024-11-24T07:12:21.813431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForBookSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") { \"passage\"<String>().let { standardNormalizeText(it) } }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForBookSummarizationAsCorpus(),\n",
    "    listOf(\"도서자료 요약\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:21.971357700Z",
     "start_time": "2024-11-24T07:12:21.877428100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForTextSummarization : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.TASK_SUMMARIZATION\n",
    "\n",
    "    private fun form(index: Int, sourceText: String, summary: String): List<ChatRow> {\n",
    "        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "        result.add(ChatRow(\"user\", summarizationInstructions[index % summarizationInstructions.size] + \"\\n\\n\" + sourceText))\n",
    "        result.add(ChatRow(\"assistant\", summary))\n",
    "\n",
    "        return result\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> = \n",
    "        data.add(\"messages\") {\n",
    "            form(\n",
    "                index=index(),\n",
    "                \"text\"<List<DataFrame<*>>>().joinToString(\"\\n\") {\n",
    "                    it.map { it[\"sentence\"] as String }.joinToString(\" \")\n",
    "                },\n",
    "                \"abstractive\"<List<String>>().joinToString(\" \").let { standardNormalizeText(it) }\n",
    "            )\n",
    "        }\n",
    "            .filterColumns(\"messages\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first()[\"documents\"] as DataFrame<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForTextSummarization(),\n",
    "    listOf(\"문서요약 텍스트\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:22.060257900Z",
     "start_time": "2024-11-24T07:12:21.975358600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForTextSummarizationAsCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> = \n",
    "        data.add(\"_text\") {\n",
    "            \"text\"<List<DataFrame<*>>>().joinToString(\"\\n\") {\n",
    "                it.map { it[\"sentence\"] as String }.joinToString(\" \")\n",
    "            }\n",
    "        }\n",
    "            .filterColumns(\"_text\")\n",
    "            .rename(\"_text\" to \"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first()[\"documents\"] as DataFrame<*>\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForTextSummarizationAsCorpus(),\n",
    "    listOf(\"문서요약 텍스트\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:22.769741500Z",
     "start_time": "2024-11-24T07:12:22.064258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForLaw : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "    \n",
    "    private data class LawInfo(\n",
    "        val caseNm: String,\n",
    "        val caseNo: String,\n",
    "        val courtNm: String,\n",
    "        val judgeDt: String\n",
    "    )\n",
    "\n",
    "    private fun infoFromDataRow(row: DataRow<*>): LawInfo = (row[\"info\"] as DataRow<*>).let {\n",
    "        LawInfo(\n",
    "            caseNm = it[\"caseNm\"] as String,\n",
    "            caseNo = it[\"caseNo\"] as String,\n",
    "            courtNm = it[\"courtNm\"] as String,\n",
    "            judgeDt = it[\"judmnAdjuDe\"] as String\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    private data class LawBody(\n",
    "        val disposal: String,\n",
    "        val mentioned: String,\n",
    "        val acusrAssrs: String,\n",
    "        val dedatAssrs: String,\n",
    "        val facts: String,\n",
    "        val decision: String,\n",
    "        val conclusion: String\n",
    "    )\n",
    "\n",
    "    private fun bodyFromDataRow(row: DataRow<*>): LawBody = LawBody(\n",
    "        disposal = ((row[\"disposal\"] as DataRow<*>)[\"disposalcontent\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") },\n",
    "        mentioned = ((row[\"mentionedItems\"] as DataRow<*>)[\"rqestObjet\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") },\n",
    "        acusrAssrs = ((row[\"assrs\"] as DataRow<*>)[\"acusrAssrs\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") }.trim(),\n",
    "        dedatAssrs = ((row[\"assrs\"] as DataRow<*>)[\"dedatAssrs\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") }.trim(),\n",
    "        facts = ((row[\"facts\"] as DataRow<*>)[\"bsisFacts\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") },\n",
    "        decision = ((row[\"dcss\"] as DataRow<*>)[\"courtDcss\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") },\n",
    "        conclusion = ((row[\"close\"] as DataRow<*>)[\"cnclsns\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") }\n",
    "    )\n",
    "\n",
    "    private fun form민사(row: DataRow<*>): String {\n",
    "        val info = infoFromDataRow(row)\n",
    "        val body = bodyFromDataRow(row)\n",
    "        \n",
    "        return \"\"\"\n",
    "        |# ${info.caseNm} [${info.courtNm} ${info.judgeDt} 선고 ${info.caseNo} 판결]\n",
    "        |## 주문\n",
    "        | ${body.disposal}\n",
    "        |\n",
    "        |## 청구취지 ${if (body.dedatAssrs.isNotBlank()) \"및 항소취지\" else \"\"}\n",
    "        | ${body.mentioned}\n",
    "        |\n",
    "        |## 이유\n",
    "        |### 기초사실\n",
    "        | ${body.facts}\n",
    "        |\n",
    "        |### 원고의 주장\n",
    "        | ${body.acusrAssrs}${if (body.dedatAssrs.isNotBlank()) \"\\n\\n### 피고의 주장\\n ${body.dedatAssrs}\" else \"\"}\n",
    "        |\n",
    "        |## 판단\n",
    "        | ${body.decision}\n",
    "        |\n",
    "        |## 결론\n",
    "        | ${body.conclusion}\n",
    "        \"\"\".trimMargin().trim().replace(\"  \", \"\")\n",
    "    }\n",
    "    \n",
    "    private fun form형사(row: DataRow<*>): String {\n",
    "        val info = infoFromDataRow(row)\n",
    "        val body = bodyFromDataRow(row)\n",
    "        \n",
    "        val reason = when {\n",
    "            body.acusrAssrs.isNotBlank() && body.dedatAssrs.isNotBlank() -> \"\"\"\n",
    "            |### 항소이유의 요지\n",
    "            |#### 피고\n",
    "            | ${body.dedatAssrs}\n",
    "            |\n",
    "            |#### 검사\n",
    "            | ${body.acusrAssrs}\n",
    "            \"\"\".trimMargin().trim().let { \"\\n${it}\\n\" }\n",
    "            body.acusrAssrs.isNotBlank() -> \"\"\"\n",
    "            |### 검사의 항소이유의 요지\n",
    "            | ${body.acusrAssrs}\n",
    "            \"\"\".trimMargin().trim().let { \"\\n${it}\\n\" }\n",
    "            body.dedatAssrs.isNotBlank() -> \"\"\"\n",
    "            |### 피고의 항소이유의 요지\n",
    "            | ${body.dedatAssrs}\n",
    "            \"\"\".trimMargin().trim().let { \"\\n${it}\\n\" }\n",
    "            else -> \"\"\n",
    "        }\n",
    "\n",
    "        return \"\"\"\n",
    "        |# ${info.caseNm} [${info.courtNm} ${info.judgeDt} 선고 ${info.caseNo} 판결]\n",
    "        |## 주문\n",
    "        | ${body.disposal}\n",
    "        |\n",
    "        |## 청구취지 ${if (body.dedatAssrs.isNotBlank()) \"및 항소취지\" else \"\"}\n",
    "        | ${body.mentioned}\n",
    "        |\n",
    "        |## 이유${reason}\n",
    "        |### 기초사실\n",
    "        | ${body.facts}\n",
    "        |\n",
    "        |## 판단\n",
    "        | ${body.decision}\n",
    "        |\n",
    "        |## 결론\n",
    "        | ${body.conclusion}\n",
    "        \"\"\".trimMargin().trim().replace(\"  \", \" \")\n",
    "    }\n",
    "\n",
    "    private fun form행정(row: DataRow<*>): String {\n",
    "        val info = infoFromDataRow(row)\n",
    "        val body = bodyFromDataRow(row)\n",
    "\n",
    "        val reason = when {\n",
    "            body.acusrAssrs.isNotBlank() && body.dedatAssrs.isNotBlank() -> \"\"\"\n",
    "            |### 항소이유의 요지\n",
    "            |#### 피고\n",
    "            | ${body.dedatAssrs}\n",
    "            |\n",
    "            |#### 원고\n",
    "            | ${body.acusrAssrs}\n",
    "            \"\"\".trimMargin().trim().let { \"\\n${it}\\n\" }\n",
    "            body.acusrAssrs.isNotBlank() -> \"\"\"\n",
    "            |### 원고의 항소이유의 요지\n",
    "            | ${body.acusrAssrs}\n",
    "            \"\"\".trimMargin().trim().let { \"\\n${it}\\n\" }\n",
    "            body.dedatAssrs.isNotBlank() -> \"\"\"\n",
    "            |### 피고의 항소이유의 요지\n",
    "            | ${body.dedatAssrs}\n",
    "            \"\"\".trimMargin().trim().let { \"\\n${it}\\n\" }\n",
    "            else -> \"\"\n",
    "        }\n",
    "\n",
    "        return \"\"\"\n",
    "        |# ${info.caseNm} [${info.courtNm} ${info.judgeDt} 선고 ${info.caseNo} 판결]\n",
    "        |## 주문\n",
    "        | ${body.disposal}\n",
    "        |\n",
    "        |## 청구취지 ${if (body.dedatAssrs.isNotBlank()) \"및 항소취지\" else \"\"}\n",
    "        | ${body.mentioned}\n",
    "        |\n",
    "        |## 이유${reason}\n",
    "        |### 기초사실\n",
    "        | ${body.facts}\n",
    "        |\n",
    "        |## 판단\n",
    "        | ${body.decision}\n",
    "        |\n",
    "        |## 결론\n",
    "        | ${body.conclusion}\n",
    "        \"\"\".trimMargin().trim().replace(\"  \", \" \")\n",
    "    }\n",
    "    \n",
    "    private data class AgreementInfo(\n",
    "        val clauseArticle: String,\n",
    "        val comparisonProvision: String?,\n",
    "        val illegalClause: String?,\n",
    "        val relatedLaw: String?\n",
    "    )\n",
    "    \n",
    "    private fun infoFromAgreement(row: DataRow<*>): AgreementInfo = AgreementInfo(\n",
    "        clauseArticle = (row[\"clauseArticle\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") },\n",
    "        comparisonProvision = if (row.containsKey(\"comProvision\")) (row[\"comProvision\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") } else null,\n",
    "        illegalClause = if (row.containsKey(\"illdcssBasiss\")) (row[\"illdcssBasiss\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") } else null,\n",
    "        relatedLaw = if (row.containsKey(\"relateLaword\")) (row[\"relateLaword\"] as List<*>).joinToString(\"\\n \") { (it as String).trim().addSuffixIfNotExists(\".\") } else null\n",
    "    )\n",
    "    \n",
    "    private fun form약관(row: DataRow<*>): String {\n",
    "        val info = infoFromAgreement(row)\n",
    "        \n",
    "        if (info.comparisonProvision != null || info.illegalClause == null || info.relatedLaw == null) {\n",
    "            // 유리\n",
    "            \n",
    "            return \"\"\"\n",
    "            |# 약관의 유불리 여부 판단\n",
    "            |## 약관\n",
    "            | ${info.clauseArticle}${if (info.comparisonProvision != null) \"\\n\\n## 비교조항\\n ${info.comparisonProvision}\" else \"\"}\n",
    "            |\n",
    "            |## 판단\n",
    "            | 위 약관은 고객에게 불리하지 않다.\n",
    "            \"\"\".trimMargin().trim()\n",
    "        } else {\n",
    "            // 불리\n",
    "            \n",
    "            return \"\"\"\n",
    "            |# 약관의 유불리 여부 판단\n",
    "            |## 약관\n",
    "            | ${info.clauseArticle}\n",
    "            |\n",
    "            |## 관련법령\n",
    "            | ${info.relatedLaw}\n",
    "            |\n",
    "            |## 판단\n",
    "            | ${info.illegalClause}\n",
    "            \"\"\".trimMargin().trim()\n",
    "        }\n",
    "    }\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.add(\"text\") {\n",
    "            when (this[\"type\"] as String) {\n",
    "                \"판결문-민사\" -> form민사(this)\n",
    "                \"판결문-형사\" -> form형사(this)\n",
    "                \"판결문-행정\" -> form행정(this)\n",
    "                \"약관\" -> form약관(this)\n",
    "                else -> \"\" // skip\n",
    "            }\n",
    "        }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val trainingLaw = file.auto().zipsJsonWalk { zip, zipFile, stream ->\n",
    "            if (zip.contains(\"판결문\")) {\n",
    "                val dataFrame = DataFrame.readJson(stream)\n",
    "                \n",
    "                val lawType = when {\n",
    "                    zipFile.contains(\"민사\") -> \"민사\"\n",
    "                    zipFile.contains(\"형사\") -> \"형사\"\n",
    "                    zipFile.contains(\"행정\") -> \"행정\"\n",
    "                    else -> return@zipsJsonWalk null\n",
    "                }\n",
    "                \n",
    "                dataFrame.add(\"type\") { \"판결문-${lawType}\" }\n",
    "            } else {\n",
    "                val dataFrame = DataFrame.readJson(stream)\n",
    "\n",
    "                dataFrame.add(\"type\") { \"약관\" }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = trainingLaw.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForLaw(),\n",
    "    listOf(\"019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터\"),\n",
    "//    showDatabase = true,\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:22.994688900Z",
     "start_time": "2024-11-24T07:12:22.775747700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForWebCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "    \n",
    "    private fun form(row: DataRow<*>): String = \"\"\"\n",
    "    |# ${(row[\"title\"] as DataFrame<*>)[\"sentence\"].toList().joinToString(\" \") { it as String }}${(row[\"subtitle\"] as DataFrame<*>)[\"sentence\"].toList().joinToString(\" \") { it as String }.let { \n",
    "        if (it.isNotBlank()) \"\\n## ${it}\" else \"\"\n",
    "    }}\n",
    "    |\n",
    "    |${(row[\"content\"] as DataFrame<*>)[\"sentence\"].toList().joinToString(\" \") { it as String }}\n",
    "    \"\"\".trimMargin().trim()\n",
    "    \n",
    "    private val replaceTarget = listOf(\n",
    "        \"[원문보기]\", \"(클릭)\"\n",
    "    )\n",
    "    \n",
    "    private val deleteTarget = listOf(\n",
    "        \"(이름)\", \"(전화번호)\"\n",
    "    )\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> = \n",
    "        data\n",
    "            .filter { deleteTarget.none { target -> it[\"text\"].toString().contains(target) } }\n",
    "            .filter { standardVaildText(it[\"text\"] as String) }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"named_entity\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "                .filter { \n",
    "                    // sentence-level filtering, if any sentence is not valid, then it should be removed\n",
    "                    (\"content\"<DataFrame<*>>()).map { \"sentence\"<String>().trim() }.all { standardVaildText(it, true) }\n",
    "                }\n",
    "                .add(\"text\") { form(this).let { standardNormalizeText(it.let { \n",
    "                    replaceTarget.fold(it) { acc, target -> acc.replace(target, \"\") }\n",
    "                }) } }\n",
    "                .filterColumns(\"text\")\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForWebCorpus(),\n",
    "    listOf(\"030.웹데이터 기반 한국어 말뭉치 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.161372400Z",
     "start_time": "2024-11-24T07:12:22.999206500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForWebSpeechCorpus : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS_SPOKEN\n",
    "\n",
    "    private fun form(row: DataRow<*>): String = (row[\"content\"] as DataFrame<*>)[\"sentence\"].toList().joinToString(\" \") { it as String }.let { standardNormalizeText(it) }\n",
    "\n",
    "    private val replaceTarget = listOf(\n",
    "        \"[원문보기]\", \"(클릭)\"\n",
    "    )\n",
    "\n",
    "    private val deleteTarget = listOf(\n",
    "        \"(이름)\", \"(전화번호)\", \"(반사회적용어)\"\n",
    "    )\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> = data.filter { deleteTarget.none { target -> it[\"text\"].toString().contains(target) } }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"named_entity\"]\n",
    "            dataFrame.asFrameColumn().concat()\n",
    "                .filter {\n",
    "                    // sentence-level filtering, if any sentence is not valid, then it should be removed\n",
    "                    (\"content\"<DataFrame<*>>()).map { \"sentence\"<String>().trim() }.all { standardVaildText(it, true) }\n",
    "                }\n",
    "                .add(\"text\") { form(this).let { standardNormalizeText(it.let {\n",
    "                    replaceTarget.fold(it) { acc, target -> acc.replace(target, \"\") }\n",
    "                }) } }\n",
    "                .filterColumns(\"text\")\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForWebSpeechCorpus(),\n",
    "    listOf(\"031.온라인 구어체 말뭉치 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.400053400Z",
     "start_time": "2024-11-24T07:12:23.168881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val personaInstructions = listOf(\n",
    "    \"다음은 두 사람의 페르소나를 활용한 대화입니다. 두 사람의 페르소나에 대한 정보는 아래와 같습니다.\\n\\n{user}\\n\\n{character}\\n\\n이제 페르소나를 활용한 대화를 시작합니다.\",\n",
    "    \"다음은 두 사람이 주어진 설정을 바탕으로 역할을 맡아 대화를 나누는 상황입니다. 두 사람의 역할에 대한 정보는 아래와 같습니다.\\n\\n{user}\\n\\n{character}\\n\\n이제 설정을 바탕으로 대화를 시작합니다.\",\n",
    "    \"{user_name}과 {character_name}은 각자의 역할을 따라 대화를 나눕니다. {user_name}과 {character_name}에 대한 정보는 아래와 같습니다.\\n\\n{user}\\n\\n{character}\\n\\n이제 역할에 따른 대화를 시작합니다.\",\n",
    "    \"역할극에 {user_name}과 {character_name}이 참여해 말하고 있습니다. {user_name}과 {character_name}에 대한 정보는 아래와 같습니다.\\n\\n{user}\\n\\n{character}\\n\\n이제 역할극을 시작합니다.\",\n",
    "    \"다음은 {user_name}과 {character_name}의 대화입니다. {user_name}과 {character_name}에 대한 정보는 아래와 같습니다.\\n\\n{user}\\n\\n{character}\\n\\n이제 대화를 시작합니다.\"\n",
    ")\n",
    "\n",
    "class PreprocessorForPersonaChat : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.CHAT\n",
    "    \n",
    "    private fun formPersona(data: DataRow<*>, name: String): String {\n",
    "        val persona = (data[\"persona\"] as DataFrame<*>)\n",
    "        \n",
    "        val entries = persona.filter {\n",
    "            if (it.containsKey(\"profile_major\") && it.containsKey(\"profile_minor\")) {\n",
    "                val major = \"profile_major\"<String>()\n",
    "                val minor = \"profile_minor\"<String?>()\n",
    "                major.isNotBlank() && minor?.isNotBlank() ?: false\n",
    "            } else {\n",
    "                false\n",
    "            }\n",
    "        }.map { \n",
    "            val major = \"profile_major\"<String>().let { standardNormalizeText(it) }\n",
    "            val minor = \"profile_minor\"<String>().let { standardNormalizeText(it) }\n",
    "            \" - ${major}: ${minor}\"\n",
    "        }.joinToString(\"\\n \")\n",
    "        \n",
    "        return \"\"\"\n",
    "        |## ${name} 프로필\n",
    "        |### 설명\n",
    "        | ${persona.map { (it[\"profile\"] as String).let { standardNormalizeText(it.addSuffixIfNotExists(\".\")) } }.joinToString(\" \")}\n",
    "        |\n",
    "        |### 설정\n",
    "        | ${entries}\n",
    "        \"\"\".trimMargin().trim()\n",
    "    }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            val personas = ((dataFrame[\"info\"] as DataRow<*>)[\"personas\"] as DataFrame<*>)\n",
    "            val user = formPersona(personas.first(), \"유저\")\n",
    "            val character = formPersona(personas.last(),\"캐릭터\")\n",
    "\n",
    "            val userId = (personas.first()[\"persona\"] as DataFrame<*>)[0][\"profile_id\"] as Int\n",
    "            \n",
    "            val conversations = dataFrame[\"utterances\"] as DataFrame<*>\n",
    "            \n",
    "            val result = mutableListOf<ChatRow>()\n",
    "\n",
    "            result.add(ChatRow(\"system\", personaInstructions[abs(conversations.hashCode()) % personaInstructions.size].replace(\"{user}\", user).replace(\"{character}\", character).replace(\"{user_name}\", \"유저\").replace(\"{character_name}\", \"캐릭터\")))\n",
    "            \n",
    "            conversations.forEach { \n",
    "                val isUser = \"persona_id\"<Int>() == userId\n",
    "                \n",
    "                val text = \"text\"<String>().let { standardNormalizeText(it) }\n",
    "                \n",
    "                result.add(ChatRow(if (isUser) \"user\" else \"assistant\", text))\n",
    "            }\n",
    "\n",
    "            result.mergeRepeating()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        return dataFrameOf(\"messages\")(*(training.toTypedArray()))\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForPersonaChat(),\n",
    "    listOf(\"044.페르소나 대화\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.481232100Z",
     "start_time": "2024-11-24T07:12:23.410134800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val topicInstructions = listOf(\n",
    "    \"다음은 {topic}에 대한 대화입니다. 당신은 {topic}에 대한 전문가이며 유저의 질문에 친절하고 정확하게 답변합니다. 이제 {topic}에 대한 대화를 시작합니다.\",\n",
    "    \"당신은 {topic}에 대한 전문가입니다.\",\n",
    "    \"{topic}에 대한 전문가로서 유저에게 {topic}에 대한 정보를 제공합니다. 이제 {topic}에 대한 대화를 시작합니다.\",\n",
    "    \"{topic}에 대한 지식을 활용해 유저에게 도움이 되는 정보를 알려 줍니다. 이제 {topic}에 대한 대화를 시작합니다.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.632446300Z",
     "start_time": "2024-11-24T07:12:23.489370300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForKnowledgeChat : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.CHAT\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            val topic = ((dataFrame[\"info\"] as DataRow<*>)[\"topic\"] as String).let { standardNormalizeText(it) }\n",
    "\n",
    "            val conversations = dataFrame[\"utterances\"] as DataFrame<*>\n",
    "\n",
    "            val result = mutableListOf<ChatRow>()\n",
    "\n",
    "            result.add(ChatRow(\"system\", topicInstructions[abs(conversations.hashCode()) % topicInstructions.size].replace(\"{topic}\", topic)))\n",
    "\n",
    "            conversations.forEach {\n",
    "                val isUser = \"role\"<String>() == \"질문자\"\n",
    "\n",
    "                val text = \"text\"<String>().let { standardNormalizeText(it) }\n",
    "\n",
    "                result.add(ChatRow(if (isUser) \"user\" else \"assistant\", text))\n",
    "            }\n",
    "\n",
    "            result.mergeRepeating()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        return dataFrameOf(\"messages\")(*(training.toTypedArray()))\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForKnowledgeChat(),\n",
    "    listOf(\"045.지식검색 대화\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.668004200Z",
     "start_time": "2024-11-24T07:12:23.636446900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val expertiseInstructions = listOf(\n",
    "    \"다음은 {topic}에 대한 대화입니다. 당신은 {topic}에 대한 전문가이며 유저의 질문에 친절하고 정확하게 답변합니다. 당신과 유저의 정보는 다음과 같습니다:\\n\\n{user}\\n\\n{character}\\n\\n이제 {topic}에 대한 대화를 시작합니다.\",\n",
    "    \"당신은 {topic}에 대한 전문가입니다.\",\n",
    "    \"{topic}에 대한 전문가로서 유저에게 {topic}에 대한 정보를 제공합니다. 당신과 유저의 정보를 참고해서 대답하세요.\\n\\n{user}\\n\\n{character}\\n\\n이제 {topic}에 대한 대화를 시작합니다.\",\n",
    "    \"{topic}에 대한 지식을 활용해 유저에게 도움이 되는 정보를 알려 줍니다. 이제 {topic}에 대한 대화를 시작합니다.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.913078900Z",
     "start_time": "2024-11-24T07:12:23.675515100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForExpertiseChat : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CHAT\n",
    "\n",
    "    private val personaMap = mapOf(\n",
    "        \"gender\" to \"성별\",\n",
    "        \"age\" to \"나이\",\n",
    "        \"occupation\" to \"직업\",\n",
    "    )\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.explode(\"messages\")\n",
    "\n",
    "    private fun formPersona(data: DataRow<*>, key: String, name: String): String {\n",
    "        val participant = (data[\"participantsInfo\"] as DataRow<*>)[key] as DataRow<*>\n",
    "        val info = (data[\"personaInfo\"] as DataRow<*>).let {\n",
    "            if (key == \"speaker1\") it[\"apprenticeInfo\"] as DataRow<*> else it[\"wizardInfo\"] as DataRow<*>\n",
    "        }[\"personaFeatures\"] as List<*>\n",
    "\n",
    "        val entries = personaMap.map { (key, value) ->\n",
    "            val entry = participant[key] as String\n",
    "            if (entry.isNotBlank()) \" - ${value}: ${entry}\" else \"\"\n",
    "        }.joinToString(\"\\n \")\n",
    "\n",
    "        return \"\"\"\n",
    "        |## ${name} 프로필\n",
    "        |### 설명\n",
    "        | ${info.joinToString(\" \") { (it as String).addSuffixIfNotExists(\".\").replace(\"챗봇\", \"전문가\") }}\n",
    "        |\n",
    "        |### 설정\n",
    "        | ${entries}\n",
    "        \"\"\".trimMargin().trim()\n",
    "    }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            val user = formPersona(dataFrame, \"speaker1\", \"유저\")\n",
    "            val character = formPersona(dataFrame, \"speaker2\", \"전문가\")\n",
    "\n",
    "            // check if there is another speaker in the data\n",
    "            if ((dataFrame[\"participantsInfo\"] as DataRow<*>).containsKey(\"speaker3\")) return@zipsJsonWalkAsync null\n",
    "\n",
    "            val conversations = dataFrame[\"sessionInfo\"] as DataFrame<*>\n",
    "\n",
    "            conversations.map {\n",
    "                val dialogs = \"dialog\"<DataFrame<*>>()\n",
    "                val topic = \"sessionKeywords\"<List<String>>().joinToString(\", \")\n",
    "\n",
    "                val result = mutableListOf<ChatRow>()\n",
    "\n",
    "                result.add(\n",
    "                    ChatRow(\n",
    "                        \"system\",\n",
    "                        expertiseInstructions[abs(dialogs.hashCode()) % expertiseInstructions.size].replace(\n",
    "                            \"{user}\",\n",
    "                            user\n",
    "                        ).replace(\"{character}\", character).replace(\"{topic}\", topic)\n",
    "                    )\n",
    "                )\n",
    "\n",
    "                dialogs.forEach {\n",
    "                    val isUser = \"speaker\"<String>() == \"speaker1\"\n",
    "\n",
    "                    val text = (it[\"utterance\"] as String).let { standardNormalizeText(it) }\n",
    "\n",
    "                    result.add(ChatRow(if (isUser) \"user\" else \"assistant\", text))\n",
    "                }\n",
    "\n",
    "                result.mergeRepeating()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        return dataFrameOf(\"messages\")(*(training.toTypedArray()))\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForExpertiseChat(),\n",
    "    listOf(\"009.전문분야_기술과학_한국어 멀티세션 데이터\", \"010.전문분야_사회과학_한국어 멀티세션 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:23.944136300Z",
     "start_time": "2024-11-24T07:12:23.918079900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "val empathyInstructions = listOf(\n",
    "    \"다음은 {relation} 관계에 있는 두 사람의 대화입니다. 당신은 {speaker_relation}의 말에 공감하며 대화합니다. 각자의 관계를 존중하며 대화를 이어나가세요. 상황: {situation} 이제 대화를 시작합니다.\",\n",
    "    \"두 사람은 {relation} 관계에 있습니다. 당신은 {speaker_relation}의 말에 공감하며 대화합니다. 서로의 관계에 주목하고 상황에 적절한 대화를 이어나가세요.\\n\\n상황: {situation}\\n\\n이제 대화를 시작합니다.\",\n",
    "    \"{relation} 관계에 있는 두 사람의 대화입니다. 당신은 {speaker_relation}의 말에 공감하며 대화합니다. 각자의 관계를 존중하며 말하세요.\\n\\n상황: {situation}\",\n",
    "    \"당신은 {speaker_relation}의 말에 공감하며 대화합니다. 서로의 {relation} 관계를 존중하며 대화하세요.\\n\\n상황: {situation}\\n\\n\",\n",
    "    \"당신은 주어진 상황에 맞춰 상대에게 공감하며 말합니다.\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:24.089870700Z",
     "start_time": "2024-11-24T07:12:23.947138400Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForEmpathyChat : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.CHAT\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            val (relation, situation, speakerRelation) = (dataFrame[\"info\"] as DataRow<*>).let {\n",
    "                listOf(it[\"relation\"] as String, it[\"situation\"] as String, it[\"speaker_relation\"] as String)\n",
    "            }\n",
    "\n",
    "            val conversations = dataFrame[\"utterances\"] as DataFrame<*>\n",
    "\n",
    "            val result = mutableListOf<ChatRow>()\n",
    "\n",
    "            result.add(ChatRow(\"system\", empathyInstructions[abs(conversations.hashCode()) % empathyInstructions.size].replace(\"{relation}\", relation).replace(\"{situation}\", situation).replace(\"{speaker_relation}\", speakerRelation)))\n",
    "\n",
    "            conversations.forEach {\n",
    "                val isUser = \"role\"<String>() == \"speaker\"\n",
    "\n",
    "                val text = \"text\"<String>().let { standardNormalizeText(it) }\n",
    "\n",
    "                result.add(ChatRow(if (isUser) \"user\" else \"assistant\", text))\n",
    "            }\n",
    "\n",
    "            result.mergeRepeating()\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        return dataFrameOf(\"messages\")(*(training.toTypedArray()))\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForEmpathyChat(),\n",
    "    listOf(\"046.공감형 대화\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:24.306967300Z",
     "start_time": "2024-11-24T07:12:24.098375600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForMultisessionChat : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CHAT\n",
    "\n",
    "    private val personaMap = mapOf(\n",
    "        \"gender\" to \"성별\",\n",
    "        \"age\" to \"나이\",\n",
    "        \"occupation\" to \"직업\",\n",
    "    )\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.explode(\"messages\")\n",
    "\n",
    "    private fun formPersona(data: DataRow<*>, key: String, name: String): String {\n",
    "        val participant = (data[\"participantsInfo\"] as DataRow<*>)[key] as DataRow<*>\n",
    "        val info = (data[\"personaInfo\"] as DataRow<*>).let { \n",
    "            if (key == \"speaker1\") it[\"clInfo\"] as DataRow<*> else it[\"cpInfo\"] as DataRow<*>\n",
    "        }[\"personaFeatures\"] as List<*>\n",
    "\n",
    "        val entries = personaMap.map { (key, value) ->\n",
    "            val entry = participant[key] as String\n",
    "            if (entry.isNotBlank()) \" - ${value}: ${entry}\" else \"\"\n",
    "        }.joinToString(\"\\n \")\n",
    "        \n",
    "        return \"\"\"\n",
    "        |## ${name} 프로필\n",
    "        |### 설명\n",
    "        | ${info.joinToString(\" \") { it as String }}\n",
    "        |\n",
    "        |### 설정\n",
    "        | ${entries}\n",
    "        \"\"\".trimMargin().trim()\n",
    "    }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalkAsync { _, z, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream).first() as DataRow<*>\n",
    "            val user = formPersona(dataFrame, \"speaker1\", \"유저\")\n",
    "            val character = formPersona(dataFrame, \"speaker2\", \"캐릭터\")\n",
    "            \n",
    "            // check if there is another speaker in the data\n",
    "            if ((dataFrame[\"participantsInfo\"] as DataRow<*>).containsKey(\"speaker3\")) return@zipsJsonWalkAsync null\n",
    "            \n",
    "            val conversations = dataFrame[\"sessionInfo\"] as DataFrame<*>\n",
    "\n",
    "            conversations.map {\n",
    "                val dialogs = \"dialog\"<DataFrame<*>>()\n",
    "\n",
    "                val result = mutableListOf<ChatRow>()\n",
    "\n",
    "                result.add(ChatRow(\"system\", personaInstructions[abs(dialogs.hashCode()) % personaInstructions.size].replace(\"{user}\", user).replace(\"{character}\", character)))\n",
    "\n",
    "                dialogs.forEach {\n",
    "                    val isUser = \"speaker\"<String>() == \"speaker1\"\n",
    "\n",
    "                    val text = (it[\"utterance\"] as String).let { standardNormalizeText(it) }\n",
    "\n",
    "                    result.add(ChatRow(if (isUser) \"user\" else \"assistant\", text))\n",
    "                }\n",
    "\n",
    "                result.mergeRepeating()\n",
    "            }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        return dataFrameOf(\"messages\")(*(training.toTypedArray()))\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForMultisessionChat(),\n",
    "    listOf(\"141.한국어 멀티세션 대화\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:24.467001600Z",
     "start_time": "2024-11-24T07:12:24.312226100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class PreprocessorForCommonSenseGeneration : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.explode(\"genSentences\")\n",
    "            .filter { \"genSentences\"<DataRow<*>>().let { it[\"label-scenes\"] as String }.let { standardVaildText(it) } }\n",
    "            .add(\"text\") { \"genSentences\"<DataRow<*>>().let { it[\"label-scenes\"] as String }.let { standardNormalizeText(it).trim() } }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "            dataFrame\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForCommonSenseGeneration(),\n",
    "    listOf(\"048.일반상식 문장 생성 데이터\"),\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:24.671712500Z",
     "start_time": "2024-11-24T07:12:24.476520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import java.nio.charset.Charset\n",
    "import kotlin.io.path.bufferedReader\n",
    "\n",
    "class PreprocessorForParrellDialect : Preprocessor {\n",
    "    override val type: PreprocessorType = PreprocessorType.DIALECT\n",
    "\n",
    "    private val locations = listOf(\n",
    "        \"강원도\",\n",
    "        \"경상도\",\n",
    "        \"충청도\",\n",
    "        \"전라도\",\n",
    "        \"제주도\"\n",
    "    )\n",
    "    \n",
    "    private fun String.punctuationCorrection() = \n",
    "        if (this.last() in correctPunctuation) this else this + \".\"\n",
    "\n",
    "    private fun form(sourceLanguage: String, targetLanguage: String, sourceText: String, targetText: String): String = \"\"\"\n",
    "    |${sourceLanguage}: ${sourceText.punctuationCorrection()}\n",
    "    |${targetLanguage}: ${targetText.punctuationCorrection()}\n",
    "    \"\"\".trimMargin().trim()\n",
    "\n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data\n",
    "            .filter { standardVaildText(\"from_text\"<String>()) && standardVaildText(\"to_text\"<String>()) }\n",
    "            // swapping source and target language (explode) (source: dialect, target: standard(original) + source: standard, target: dialect)\n",
    "            .let {\n",
    "//                it.concat(\n",
    "//                    dataFrameOf(\"from\", \"to\", \"from_text\", \"to_text\")(\n",
    "//                        it[\"to\"].toList(),\n",
    "//                        it[\"from\"].toList(),\n",
    "//                        it[\"to_text\"].toList(),\n",
    "//                        it[\"from_text\"].toList()\n",
    "//                    )\n",
    "//                )\n",
    "                it.concat(\n",
    "                    it.mapToFrame {\n",
    "                        \"from\" from it[\"to\"]\n",
    "                        \"to\" from it[\"from\"]\n",
    "                        \"from_text\" from it[\"to_text\"]\n",
    "                        \"to_text\" from it[\"from_text\"]\n",
    "                    }\n",
    "                )\n",
    "            }\n",
    "            .add(\"text\") { form(\"from\"<String>(), \"to\"<String>(), \"from_text\"<String>(), \"to_text\"<String>()) }\n",
    "//            .let { it.remove(*(it.columnNames() - listOf(\"from\", \"to\", \"from_text\", \"to_text\")).toTypedArray()) }\n",
    "            .filterColumns(\"text\")\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = file.auto().zipsJsonWalk { zipFile, _, stream ->\n",
    "            val dialect = locations.firstOrNull { zipFile.contains(it) } ?: return@zipsJsonWalk null\n",
    "            val dataFrame = DataFrame.readJson(stream)\n",
    "\n",
    "            (dataFrame\n",
    "                .first()[\"transcription\"] as DataRow<*>)\n",
    "                .let {\n",
    "                    // keep only dialect, standard field\n",
    "                    it.df().remove(*(it.columnNames() - listOf(\"dialect\", \"standard\")).toTypedArray())\n",
    "                        .add(\"from\") { \"${dialect} 사투리\" }\n",
    "                        .add(\"to\") { \"표준어\" }\n",
    "                        .rename(\"dialect\" to \"from_text\", \"standard\" to \"to_text\")\n",
    "                }.first() \n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForParrellDialect(),\n",
    "    listOf(\"139-1.중·노년층 한국어 방언 데이터 (강원도, 경상도)\", \"139-2.중·노년층 한국어 방언 데이터 (충청도, 전라도, 제주도)\"),\n",
    "    showDatabase = false,\n",
    "    showExamples = true,\n",
    "    fast = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:24.774080600Z",
     "start_time": "2024-11-24T07:12:24.680231500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "/**\n",
    " * [모두의 말뭉치](https://kli.korean.go.kr/corpus/)\n",
    " */\n",
    "class PreprocessorForModuCorpusText : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.CORPUS\n",
    "    \n",
    "    private fun form(title: String, content: String): String = \"\"\"\n",
    "    |## ${title}\n",
    "    |${content}\n",
    "    \"\"\".trimMargin().trim()\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = listOf(file).zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"document\"].asFrameColumn().concat()\n",
    "            dataFrame\n",
    "                .mapToFrame {\n",
    "                    \"text\" from {\n",
    "                        val df = \"paragraph\"<DataFrame<*>>().map { \"form\"<String>() }\n",
    "\n",
    "                        form(\n",
    "                            df[0],\n",
    "                            df.drop(1).joinToString(\"\\n\").let { \" \" + standardNormalizeText(it) }\n",
    "                        )\n",
    "                    }\n",
    "                }\n",
    "                .filter { standardVaildText(\"text\"<String>()) }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForModuCorpusText(),\n",
    "    listOf(\"NIKL_NEWSPAPER_2020_v1.1_JSON.zip\", \"NIKL_NEWSPAPER_2021_v1.0_JSON.zip\", \"NIKLNEWSPAPER_2022_v1.0_JSON.zip\", \"NIKL_NEWSPAPER_2023_JSON_v1.0.zip\", \"NIKL_NEWSPAPER_v2.0_JSON.zip\", \"NIKL_WRITTEN_v1.2_JSON.zip\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:24.993946700Z",
     "start_time": "2024-11-24T07:12:24.778081600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kotlin.collections.last as kLast\n",
    "\n",
    "val personaTopicInstructions = listOf(\n",
    "    \"다음은 {relation} 관계에 있는 두 사람의 {topic}에 대한 대화입니다. 두 사람의 대화 내용에 주목하며 대화를 이어나가세요. 이제 대화를 시작합니다.\",\n",
    "    \"두 사람은 {relation} 관계에 있습니다. {topic}에 대한 대화를 이어나가세요. 이제 대화를 시작합니다.\",\n",
    "    \"{topic}에 대해 두 {relation} 관계에 있는 사람이 대화를 나눕니다. 각자의 관계를 존중하며 대화를 이어나가세요. 이제 대화를 시작합니다.\",\n",
    "    \"{topic}에 대해 두 사람이 서로 말하고 있습니다. 주제에 어긋나지 않도록 자연스러운 대화를 이어나가세요. 이제 대화를 시작합니다.\",\n",
    ")\n",
    "\n",
    "/**\n",
    " * [모두의 말뭉치](https://kli.korean.go.kr/corpus/)\n",
    " */\n",
    "class PreprocessorForModuCorpusChat : PreprocessorWithoutPreprocessing() {\n",
    "    override val type: PreprocessorType = PreprocessorType.CHAT\n",
    "\n",
    "    private val personaMap = mapOf(\n",
    "        \"sex\" to \"성별\",\n",
    "        \"age\" to \"나이\",\n",
    "        \"occupation\" to \"직업\",\n",
    "    )\n",
    "    \n",
    "    override fun preprocess(data: DataFrame<*>): DataFrame<*> =\n",
    "        data.explode(\"messages\")\n",
    "\n",
    "    private fun formPersona(data: DataRow<*>, key: Int, name: String): Pair<String, String> {\n",
    "        val participant = ((data[\"metadata\"] as DataRow<*>)[\"speaker\"] as DataFrame<*>)[key] as DataRow<*>\n",
    "        val id = participant[\"id\"] as String\n",
    "\n",
    "        val entries = personaMap.map { (key, value) ->\n",
    "            val entry = participant[key] as String\n",
    "            if (entry.isNotBlank()) \" - ${value}: ${entry}\" else \"\"\n",
    "        }.joinToString(\"\\n \")\n",
    "\n",
    "        return \"\"\"\n",
    "        |## ${name} 프로필\n",
    "        |### 설정\n",
    "        | ${entries}\n",
    "        \"\"\".trimMargin().trim() to id\n",
    "    }\n",
    "\n",
    "    override fun read(file: File): DataFrame<*> {\n",
    "        val training = listOf(file).zipsJsonWalk { _, _, stream ->\n",
    "            val dataFrame = DataFrame.readJson(stream)[\"document\"].asFrameColumn().concat()\n",
    "\n",
    "            dataFrame\n",
    "                .filter {\n",
    "                    // speaker must be two\n",
    "                    ((it[\"metadata\"] as DataRow<*>)[\"speaker\"] as DataFrame<*>).rowsCount() == 2\n",
    "                }\n",
    "                .mapToFrame {\n",
    "                    \"messages\" from {\n",
    "                        val (user, userId) = formPersona(it, 0, \"유저\")\n",
    "                        val (character, _) = formPersona(it, 1, \"캐릭터\")\n",
    "\n",
    "                        val relation =\n",
    "                            \"metadata\"<DataRow<*>>().run { \"setting\"<DataRow<*>>() }[\"relation\"] as String\n",
    "                        val topic = (\"metadata\"<DataRow<*>>()[\"topic\"] as String).split(\">\").kLast().trim()\n",
    "\n",
    "                        val result = mutableListOf<ChatRow>()\n",
    "\n",
    "                        result.add(ChatRow(\"system\", personaTopicInstructions[abs((relation + topic).hashCode()) % personaTopicInstructions.size].replace(\"{relation}\", relation).replace(\"{topic}\", topic)))\n",
    "\n",
    "                        \"utterance\"<DataFrame<*>>().forEach {\n",
    "                            val isUser = \"speaker_id\"<String>() == userId\n",
    "\n",
    "                            val text = \"form\"<String>().let { standardNormalizeText(it) }\n",
    "\n",
    "                            result.add(ChatRow(if (isUser) \"user\" else \"assistant\", text))\n",
    "                        }\n",
    "\n",
    "                        result.mergeRepeating()\n",
    "                    }\n",
    "                }\n",
    "        }\n",
    "\n",
    "        // merge all dataframes\n",
    "        val data = training.concat()\n",
    "        return data\n",
    "    }\n",
    "}\n",
    "\n",
    "declarePreprocessor(\n",
    "    PreprocessorForModuCorpusChat(),\n",
    "    listOf(\"NIKL_DIALOGUE_2020_v1.4.zip\", \"NIKL_DIALOGUE_2021_v1.1.zip\", \"NIKL_DIALOGUE_2022_v1.0_JSON.zip\"),\n",
    "    showExamples = true\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:25.056213100Z",
     "start_time": "2024-11-24T07:12:25.000456600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "// find not preprocessed files\n",
    "\n",
    "val notPreprocessed = files.filter { it !in preprocessors.keys }\n",
    "notPreprocessed"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:25.101782800Z",
     "start_time": "2024-11-24T07:12:25.061724400Z"
    }
   },
   "cell_type": "code",
   "source": "files",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[009.전문분야_기술과학_한국어 멀티세션 데이터, 010.전문분야_사회과학_한국어 멀티세션 데이터, 016.행정 문서 대상 기계독해 데이터, 017.뉴스 기사 기계독해 데이터, 018.논문자료 요약 데이터, 019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터, 021.도서자료 기계독해, 022.요약문 및 레포트 생성 데이터, 023.방송 콘텐츠 대본 요약 데이터, 025.일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터, 026.기술과학 분야 한-영 번역 병렬 말뭉치 데이터, 027.일상생활 및 구어체 한-중, 한-일 번역 병렬 말뭉치 데이터, 028.다국어 구어체 번역 병렬 말뭉치 데이터, 029.대규모 구매도서 기반 한국어 말뭉치 데이터, 030.웹데이터 기반 한국어 말뭉치 데이터, 031.온라인 구어체 말뭉치 데이터, 032.방송콘텐츠 한국어-영어 번역 말뭉치, 034.방송콘텐츠 한국어-유럽어 번역 말뭉치, 036.방송콘텐츠 한국어-아시아어 번역 말뭉치, 044.페르소나 대화, 045.지식검색 대화, 046.공감형 대화, 048.일반상식 문장 생성 데이터, 053.한국어-다국어(영어 제외) 번역 말뭉치(기술과학), 054.한국어-다국어 번역 말뭉치(기초과학), 055.한국어-다국어 번역 말뭉치(인문학), 119.국가기록물 대상 초거대AI 학습을 위한 말뭉치 데이터, 121.한국어 성능이 개선된 초거대AI 언어모델 개발 및 데이터, 141.한국어 멀티세션 대화, 150.숫자연산 기계독해 데이터, 152.기술과학 문서 기계독해 데이터, 153.기술과학 요약 데이터, 155.산업정보 연계 주요국 특허 영-한 데이터, 156.전문분야 영-한, 중-한 번역 말뭉치(식품), 157.방송 콘텐츠 한-중, 한-일 번역 병렬 말뭉치 데이터, 157.추상 요약 사실성 검증 데이터, NIKLNEWSPAPER_2022_v1.0_JSON.zip, NIKL_DIALOGUE_2020_v1.4.zip, NIKL_DIALOGUE_2021_v1.1.zip, NIKL_DIALOGUE_2022_v1.0_JSON.zip, NIKL_NEWSPAPER_2020_v1.1_JSON.zip, NIKL_NEWSPAPER_2021_v1.0_JSON.zip, NIKL_NEWSPAPER_2023_JSON_v1.0.zip, NIKL_NEWSPAPER_v2.0_JSON.zip, NIKL_WRITTEN_v1.2_JSON.zip, 기계독해, 도서자료 요약, 문서요약 텍스트]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:14:05.710594300Z",
     "start_time": "2024-11-24T07:14:05.667027700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fun grammarMistakeVisualize() {\n",
    "    val df = dataFrameOf(\n",
    "        \"wrong\" to commonGrammarMistakes.keys.toList(),\n",
    "        \"correct\" to commonGrammarMistakes.values.toList(),\n",
    "        \"count\" to commonGrammarMistakesStatistics.values.map { it.second }.toList()\n",
    "    )\n",
    "\n",
    "    println(df)\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T08:12:20.148599300Z",
     "start_time": "2024-11-24T07:14:06.411810500Z"
    }
   },
   "cell_type": "code",
   "source": [
    "// all preprocessors are written.\n",
    "\n",
    "val preprocessedDir = File(\"preprocessed\").also { \n",
    "    if (!it.exists()) it.mkdirs()\n",
    "}\n",
    "\n",
    "files.forEach {\n",
    "    val preprocessor = preprocessors[it] ?: return@forEach\n",
    "    preprocessor.forEach { type, processor ->\n",
    "        println(\"Preprocessing ${it} for ${type}\")\n",
    "\n",
    "        val file = File(preprocessedDir, \"/${type}/${it}.jsonl\").also {\n",
    "            if (!it.parentFile.exists()) it.parentFile.mkdirs()\n",
    "            if (!it.exists()) it.createNewFile()\n",
    "            else return@forEach\n",
    "        }\n",
    "        \n",
    "        processor.read(\n",
    "            File(\"./datasets/${it}\")\n",
    "        ).let {\n",
    "            if (processor is PreprocessorWithoutPreprocessing) it\n",
    "            else processor.preprocess(it)\n",
    "        }.let @OptIn(ExperimentalSerializationApi::class) @Suppress(\"UNCHECKED_CAST\") {\n",
    "            // check if text column exists\n",
    "            if (\"text\" in it.columnNames()) {\n",
    "                val textList = (it.toMap() as Map<String, List<String>>)[\"text\"]!!\n",
    "                println(\"Writing ${textList.size} rows to ${file}\")\n",
    "                // write by rows\n",
    "                file.bufferedWriter().use { writer ->\n",
    "                    textList.forEach { text ->\n",
    "                        writer.write(Json.encodeToString(mapOf(\"text\" to text)))\n",
    "                        writer.newLine()\n",
    "                    }\n",
    "                }\n",
    "            } else if (\"messages\" in it.columnNames()) {\n",
    "//                Json.encodeToStream(it.toMap() as Map<String, List<List<ChatRow>>>, file.outputStream())\n",
    "                val messages = (it.toMap() as Map<String, List<List<ChatRow>>>)[\"messages\"]!!\n",
    "                println(\"Writing ${messages.size} rows to ${file}\")\n",
    "                file.bufferedWriter().use { writer ->\n",
    "                    messages.forEach { message ->\n",
    "                        writer.write(Json.encodeToString(mapOf(\"messages\" to message)))\n",
    "                        writer.newLine()\n",
    "                    }\n",
    "                }\n",
    "            } else {\n",
    "                println(\"Text column does not exist in the dataframe.\")\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    grammarMistakeVisualize()\n",
    "}\n",
    "\n",
    "println(\"All files are preprocessed.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing 009.전문분야_기술과학_한국어 멀티세션 데이터 for CHAT\r\n",
      "Writing 120097 rows to preprocessed\\CHAT\\009.전문분야_기술과학_한국어 멀티세션 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠  9232\n",
      "  1  는 커녕     는커녕     0\n",
      "  2  은 커녕     은커녕     0\n",
      "  3    라고      라고    99\n",
      "  4    부터      부터    66\n",
      "  5   투성이     투성이     5\n",
      "  6    짜리      짜리    27\n",
      "  7    어치      어치     4\n",
      "  8   할려고     하려고     6\n",
      "  9   어떻해     어떡해     1\n",
      " 10   어짜피     어차피     0\n",
      " 11   곰곰히     곰곰이     6\n",
      " 12    요세      요새    69\n",
      " 13    금새      금세    61\n",
      " 14     왠       웬   166\n",
      " 15    웬지      왠지   164\n",
      " 16  오랫만에    오랜만에    19\n",
      " 17   일일히     일일이     6\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 010.전문분야_사회과학_한국어 멀티세션 데이터 for CHAT\r\n",
      "Writing 120761 rows to preprocessed\\CHAT\\010.전문분야_사회과학_한국어 멀티세션 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15622\n",
      "  1  는 커녕     는커녕     0\n",
      "  2  은 커녕     은커녕     0\n",
      "  3    라고      라고   248\n",
      "  4    부터      부터   339\n",
      "  5   투성이     투성이    14\n",
      "  6    짜리      짜리    30\n",
      "  7    어치      어치     9\n",
      "  8   할려고     하려고    75\n",
      "  9   어떻해     어떡해     2\n",
      " 10   어짜피     어차피     1\n",
      " 11   곰곰히     곰곰이    14\n",
      " 12    요세      요새   109\n",
      " 13    금새      금세    75\n",
      " 14     왠       웬   566\n",
      " 15    웬지      왠지   553\n",
      " 16  오랫만에    오랜만에   126\n",
      " 17   일일히     일일이     9\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 016.행정 문서 대상 기계독해 데이터 for CORPUS\r\n",
      "Writing 197698 rows to preprocessed\\CORPUS\\016.행정 문서 대상 기계독해 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15626\n",
      "  1  는 커녕     는커녕     1\n",
      "  2  은 커녕     은커녕     2\n",
      "  3    라고      라고   666\n",
      "  4    부터      부터  1253\n",
      "  5   투성이     투성이    17\n",
      "  6    짜리      짜리    30\n",
      "  7    어치      어치    18\n",
      "  8   할려고     하려고    76\n",
      "  9   어떻해     어떡해     2\n",
      " 10   어짜피     어차피     1\n",
      " 11   곰곰히     곰곰이    14\n",
      " 12    요세      요새   123\n",
      " 13    금새      금세    84\n",
      " 14     왠       웬   570\n",
      " 15    웬지      왠지   556\n",
      " 16  오랫만에    오랜만에   127\n",
      " 17   일일히     일일이     9\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 017.뉴스 기사 기계독해 데이터 for CORPUS\r\n",
      "Writing 159968 rows to preprocessed\\CORPUS\\017.뉴스 기사 기계독해 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15629\n",
      "  1  는 커녕     는커녕    19\n",
      "  2  은 커녕     은커녕    31\n",
      "  3    라고      라고   815\n",
      "  4    부터      부터  1597\n",
      "  5   투성이     투성이    38\n",
      "  6    짜리      짜리    85\n",
      "  7    어치      어치   146\n",
      "  8   할려고     하려고    79\n",
      "  9   어떻해     어떡해     2\n",
      " 10   어짜피     어차피     3\n",
      " 11   곰곰히     곰곰이    16\n",
      " 12    요세      요새   128\n",
      " 13    금새      금세   134\n",
      " 14     왠       웬   642\n",
      " 15    웬지      왠지   626\n",
      " 16  오랫만에    오랜만에   130\n",
      " 17   일일히     일일이    16\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 018.논문자료 요약 데이터 for TASK_SUMMARIZATION\r\n",
      "Writing 678774 rows to preprocessed\\TASK_SUMMARIZATION\\018.논문자료 요약 데이터.jsonl\r\n",
      "Preprocessing 018.논문자료 요약 데이터 for CORPUS\r\n",
      "Writing 678758 rows to preprocessed\\CORPUS\\018.논문자료 요약 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15788\n",
      "  1  는 커녕     는커녕    85\n",
      "  2  은 커녕     은커녕    71\n",
      "  3    라고      라고  7737\n",
      "  4    부터      부터 13344\n",
      "  5   투성이     투성이    58\n",
      "  6    짜리      짜리   168\n",
      "  7    어치      어치   168\n",
      "  8   할려고     하려고   141\n",
      "  9   어떻해     어떡해    10\n",
      " 10   어짜피     어차피     3\n",
      " 11   곰곰히     곰곰이    16\n",
      " 12    요세      요새   500\n",
      " 13    금새      금세   222\n",
      " 14     왠       웬   712\n",
      " 15    웬지      왠지   684\n",
      " 16  오랫만에    오랜만에   132\n",
      " 17   일일히     일일이   635\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터 for CORPUS\r\n",
      "Writing 16000 rows to preprocessed\\CORPUS\\019.법률, 규정 (판결서, 약관 등) 텍스트 분석 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15788\n",
      "  1  는 커녕     는커녕    85\n",
      "  2  은 커녕     은커녕    71\n",
      "  3    라고      라고  7737\n",
      "  4    부터      부터 13344\n",
      "  5   투성이     투성이    58\n",
      "  6    짜리      짜리   168\n",
      "  7    어치      어치   168\n",
      "  8   할려고     하려고   141\n",
      "  9   어떻해     어떡해    10\n",
      " 10   어짜피     어차피     3\n",
      " 11   곰곰히     곰곰이    16\n",
      " 12    요세      요새   500\n",
      " 13    금새      금세   222\n",
      " 14     왠       웬   712\n",
      " 15    웬지      왠지   684\n",
      " 16  오랫만에    오랜만에   132\n",
      " 17   일일히     일일이   635\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 021.도서자료 기계독해 for CORPUS\r\n",
      "Writing 5368 rows to preprocessed\\CORPUS\\021.도서자료 기계독해.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15788\n",
      "  1  는 커녕     는커녕    85\n",
      "  2  은 커녕     은커녕    71\n",
      "  3    라고      라고  7743\n",
      "  4    부터      부터 13358\n",
      "  5   투성이     투성이    58\n",
      "  6    짜리      짜리   168\n",
      "  7    어치      어치   168\n",
      "  8   할려고     하려고   141\n",
      "  9   어떻해     어떡해    10\n",
      " 10   어짜피     어차피     3\n",
      " 11   곰곰히     곰곰이    16\n",
      " 12    요세      요새   500\n",
      " 13    금새      금세   223\n",
      " 14     왠       웬   713\n",
      " 15    웬지      왠지   685\n",
      " 16  오랫만에    오랜만에   132\n",
      " 17   일일히     일일이   635\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 022.요약문 및 레포트 생성 데이터 for TASK_SUMMARIZATION\r\n",
      "Writing 146771 rows to preprocessed\\TASK_SUMMARIZATION\\022.요약문 및 레포트 생성 데이터.jsonl\r\n",
      "Preprocessing 022.요약문 및 레포트 생성 데이터 for CORPUS\r\n",
      "Writing 146771 rows to preprocessed\\CORPUS\\022.요약문 및 레포트 생성 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15796\n",
      "  1  는 커녕     는커녕   121\n",
      "  2  은 커녕     은커녕   110\n",
      "  3    라고      라고 10841\n",
      "  4    부터      부터 13771\n",
      "  5   투성이     투성이   150\n",
      "  6    짜리      짜리   310\n",
      "  7    어치      어치   388\n",
      "  8   할려고     하려고   152\n",
      "  9   어떻해     어떡해    10\n",
      " 10   어짜피     어차피     6\n",
      " 11   곰곰히     곰곰이    18\n",
      " 12    요세      요새   512\n",
      " 13    금새      금세   245\n",
      " 14     왠       웬  1103\n",
      " 15    웬지      왠지  1068\n",
      " 16  오랫만에    오랜만에   132\n",
      " 17   일일히     일일이   639\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     0\n",
      "...\n",
      "\r\n",
      "Preprocessing 023.방송 콘텐츠 대본 요약 데이터 for TASK_SUMMARIZATION\r\n",
      "Writing 84364 rows to preprocessed\\TASK_SUMMARIZATION\\023.방송 콘텐츠 대본 요약 데이터.jsonl\r\n",
      "Preprocessing 023.방송 콘텐츠 대본 요약 데이터 for CORPUS\r\n",
      "Writing 84364 rows to preprocessed\\CORPUS\\023.방송 콘텐츠 대본 요약 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15799\n",
      "  1  는 커녕     는커녕   150\n",
      "  2  은 커녕     은커녕   134\n",
      "  3    라고      라고 11681\n",
      "  4    부터      부터 13849\n",
      "  5   투성이     투성이   177\n",
      "  6    짜리      짜리   368\n",
      "  7    어치      어치   414\n",
      "  8   할려고     하려고   375\n",
      "  9   어떻해     어떡해    17\n",
      " 10   어짜피     어차피     7\n",
      " 11   곰곰히     곰곰이    22\n",
      " 12    요세      요새   516\n",
      " 13    금새      금세   253\n",
      " 14     왠       웬  1922\n",
      " 15    웬지      왠지  1703\n",
      " 16  오랫만에    오랜만에   134\n",
      " 17   일일히     일일이   641\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     3\n",
      "...\n",
      "\r\n",
      "Preprocessing 025.일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터 for TASK_TRANSLATION\r\n",
      "Writing 2267244 rows to preprocessed\\TASK_TRANSLATION\\025.일상생활 및 구어체 한-영 번역 병렬 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15834\n",
      "  1  는 커녕     는커녕   152\n",
      "  2  은 커녕     은커녕   138\n",
      "  3    라고      라고 11813\n",
      "  4    부터      부터 14284\n",
      "  5   투성이     투성이   190\n",
      "  6    짜리      짜리   477\n",
      "  7    어치      어치   426\n",
      "  8   할려고     하려고   414\n",
      "  9   어떻해     어떡해    26\n",
      " 10   어짜피     어차피    13\n",
      " 11   곰곰히     곰곰이    25\n",
      " 12    요세      요새   529\n",
      " 13    금새      금세   310\n",
      " 14     왠       웬  2094\n",
      " 15    웬지      왠지  1859\n",
      " 16  오랫만에    오랜만에   140\n",
      " 17   일일히     일일이   653\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     3\n",
      "...\n",
      "\r\n",
      "Preprocessing 026.기술과학 분야 한-영 번역 병렬 말뭉치 데이터 for TASK_TRANSLATION\r\n",
      "Writing 1200140 rows to preprocessed\\TASK_TRANSLATION\\026.기술과학 분야 한-영 번역 병렬 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 15836\n",
      "  1  는 커녕     는커녕   184\n",
      "  2  은 커녕     은커녕   154\n",
      "  3    라고      라고 11906\n",
      "  4    부터      부터 14519\n",
      "  5   투성이     투성이   196\n",
      "  6    짜리      짜리   545\n",
      "  7    어치      어치   494\n",
      "  8   할려고     하려고   414\n",
      "  9   어떻해     어떡해    26\n",
      " 10   어짜피     어차피    13\n",
      " 11   곰곰히     곰곰이    25\n",
      " 12    요세      요새   582\n",
      " 13    금새      금세   317\n",
      " 14     왠       웬  2100\n",
      " 15    웬지      왠지  1869\n",
      " 16  오랫만에    오랜만에   140\n",
      " 17   일일히     일일이   658\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     3\n",
      "...\n",
      "\r\n",
      "Preprocessing 027.일상생활 및 구어체 한-중, 한-일 번역 병렬 말뭉치 데이터 for TASK_TRANSLATION\r\n",
      "Writing 2305332 rows to preprocessed\\TASK_TRANSLATION\\027.일상생활 및 구어체 한-중, 한-일 번역 병렬 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 16117\n",
      "  1  는 커녕     는커녕   197\n",
      "  2  은 커녕     은커녕   161\n",
      "  3    라고      라고 12164\n",
      "  4    부터      부터 15661\n",
      "  5   투성이     투성이   225\n",
      "  6    짜리      짜리   737\n",
      "  7    어치      어치   531\n",
      "  8   할려고     하려고   779\n",
      "  9   어떻해     어떡해    48\n",
      " 10   어짜피     어차피    36\n",
      " 11   곰곰히     곰곰이    33\n",
      " 12    요세      요새   594\n",
      " 13    금새      금세   343\n",
      " 14     왠       웬  2435\n",
      " 15    웬지      왠지  2108\n",
      " 16  오랫만에    오랜만에   177\n",
      " 17   일일히     일일이   659\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     3\n",
      "...\n",
      "\r\n",
      "Preprocessing 028.다국어 구어체 번역 병렬 말뭉치 데이터 for TASK_TRANSLATION\r\n",
      "Writing 2387510 rows to preprocessed\\TASK_TRANSLATION\\028.다국어 구어체 번역 병렬 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 16385\n",
      "  1  는 커녕     는커녕   201\n",
      "  2  은 커녕     은커녕   165\n",
      "  3    라고      라고 12334\n",
      "  4    부터      부터 17215\n",
      "  5   투성이     투성이   230\n",
      "  6    짜리      짜리   874\n",
      "  7    어치      어치   570\n",
      "  8   할려고     하려고  1239\n",
      "  9   어떻해     어떡해    74\n",
      " 10   어짜피     어차피    77\n",
      " 11   곰곰히     곰곰이    35\n",
      " 12    요세      요새   649\n",
      " 13    금새      금세   368\n",
      " 14     왠       웬  2816\n",
      " 15    웬지      왠지  2337\n",
      " 16  오랫만에    오랜만에   244\n",
      " 17   일일히     일일이   660\n",
      " 18  희안하다    희한하다     0\n",
      " 19   희안한     희한한     3\n",
      "...\n",
      "\r\n",
      "Preprocessing 029.대규모 구매도서 기반 한국어 말뭉치 데이터 for CORPUS\r\n",
      "Writing 29363383 rows to preprocessed\\CORPUS\\029.대규모 구매도서 기반 한국어 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 16808\n",
      "  1  는 커녕     는커녕  1215\n",
      "  2  은 커녕     은커녕   859\n",
      "  3    라고      라고 52896\n",
      "  4    부터      부터 22904\n",
      "  5   투성이     투성이  2567\n",
      "  6    짜리      짜리  2876\n",
      "  7    어치      어치  1681\n",
      "  8   할려고     하려고  1693\n",
      "  9   어떻해     어떡해   138\n",
      " 10   어짜피     어차피   165\n",
      " 11   곰곰히     곰곰이   621\n",
      " 12    요세      요새  2312\n",
      " 13    금새      금세  2789\n",
      " 14     왠       웬 63824\n",
      " 15    웬지      왠지 62956\n",
      " 16  오랫만에    오랜만에   557\n",
      " 17   일일히     일일이   773\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   149\n",
      "...\n",
      "\r\n",
      "Preprocessing 030.웹데이터 기반 한국어 말뭉치 데이터 for CORPUS\r\n",
      "Writing 4878 rows to preprocessed\\CORPUS\\030.웹데이터 기반 한국어 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 16809\n",
      "  1  는 커녕     는커녕  1222\n",
      "  2  은 커녕     은커녕   866\n",
      "  3    라고      라고 53034\n",
      "  4    부터      부터 22978\n",
      "  5   투성이     투성이  2584\n",
      "  6    짜리      짜리  2884\n",
      "  7    어치      어치  1683\n",
      "  8   할려고     하려고  1693\n",
      "  9   어떻해     어떡해   138\n",
      " 10   어짜피     어차피   166\n",
      " 11   곰곰히     곰곰이   621\n",
      " 12    요세      요새  2316\n",
      " 13    금새      금세  2816\n",
      " 14     왠       웬 64124\n",
      " 15    웬지      왠지 63232\n",
      " 16  오랫만에    오랜만에   564\n",
      " 17   일일히     일일이   773\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   150\n",
      "...\n",
      "\r\n",
      "Preprocessing 031.온라인 구어체 말뭉치 데이터 for CORPUS_SPOKEN\r\n",
      "Writing 497111 rows to preprocessed\\CORPUS_SPOKEN\\031.온라인 구어체 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17034\n",
      "  1  는 커녕     는커녕  1260\n",
      "  2  은 커녕     은커녕   903\n",
      "  3    라고      라고 55645\n",
      "  4    부터      부터 24249\n",
      "  5   투성이     투성이  2614\n",
      "  6    짜리      짜리  3009\n",
      "  7    어치      어치  1691\n",
      "  8   할려고     하려고  1984\n",
      "  9   어떻해     어떡해   265\n",
      " 10   어짜피     어차피   231\n",
      " 11   곰곰히     곰곰이   654\n",
      " 12    요세      요새  2365\n",
      " 13    금새      금세  2857\n",
      " 14     왠       웬 65947\n",
      " 15    웬지      왠지 64696\n",
      " 16  오랫만에    오랜만에   711\n",
      " 17   일일히     일일이   827\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   159\n",
      "...\n",
      "\r\n",
      "Preprocessing 032.방송콘텐츠 한국어-영어 번역 말뭉치 for TASK_TRANSLATION\r\n",
      "Merging all json files... temporary file: C:\\Users\\2A04~1\\AppData\\Local\\Temp\\3422920689201476050.tmp\r\n",
      "Writing 1559656 rows to preprocessed\\TASK_TRANSLATION\\032.방송콘텐츠 한국어-영어 번역 말뭉치.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17053\n",
      "  1  는 커녕     는커녕  1284\n",
      "  2  은 커녕     은커녕   926\n",
      "  3    라고      라고 57158\n",
      "  4    부터      부터 24760\n",
      "  5   투성이     투성이  2670\n",
      "  6    짜리      짜리  3147\n",
      "  7    어치      어치  1730\n",
      "  8   할려고     하려고  2029\n",
      "  9   어떻해     어떡해   270\n",
      " 10   어짜피     어차피   232\n",
      " 11   곰곰히     곰곰이   667\n",
      " 12    요세      요새  2426\n",
      " 13    금새      금세  2906\n",
      " 14     왠       웬 66524\n",
      " 15    웬지      왠지 65246\n",
      " 16  오랫만에    오랜만에   715\n",
      " 17   일일히     일일이   855\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   173\n",
      "...\n",
      "\r\n",
      "Preprocessing 034.방송콘텐츠 한국어-유럽어 번역 말뭉치 for TASK_TRANSLATION\r\n",
      "Merging all json files... temporary file: C:\\Users\\2A04~1\\AppData\\Local\\Temp\\16678797985106087405.tmp\r\n",
      "Writing 1560587 rows to preprocessed\\TASK_TRANSLATION\\034.방송콘텐츠 한국어-유럽어 번역 말뭉치.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17071\n",
      "  1  는 커녕     는커녕  1307\n",
      "  2  은 커녕     은커녕   948\n",
      "  3    라고      라고 58594\n",
      "  4    부터      부터 25248\n",
      "  5   투성이     투성이  2733\n",
      "  6    짜리      짜리  3287\n",
      "  7    어치      어치  1770\n",
      "  8   할려고     하려고  2069\n",
      "  9   어떻해     어떡해   274\n",
      " 10   어짜피     어차피   234\n",
      " 11   곰곰히     곰곰이   680\n",
      " 12    요세      요새  2473\n",
      " 13    금새      금세  2960\n",
      " 14     왠       웬 67076\n",
      " 15    웬지      왠지 65773\n",
      " 16  오랫만에    오랜만에   720\n",
      " 17   일일히     일일이   881\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   188\n",
      "...\n",
      "\r\n",
      "Preprocessing 036.방송콘텐츠 한국어-아시아어 번역 말뭉치 for TASK_TRANSLATION\r\n",
      "Writing 2322093 rows to preprocessed\\TASK_TRANSLATION\\036.방송콘텐츠 한국어-아시아어 번역 말뭉치.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17109\n",
      "  1  는 커녕     는커녕  1353\n",
      "  2  은 커녕     은커녕  1009\n",
      "  3    라고      라고 60739\n",
      "  4    부터      부터 26039\n",
      "  5   투성이     투성이  2824\n",
      "  6    짜리      짜리  3595\n",
      "  7    어치      어치  1815\n",
      "  8   할려고     하려고  2706\n",
      "  9   어떻해     어떡해   294\n",
      " 10   어짜피     어차피   237\n",
      " 11   곰곰히     곰곰이   695\n",
      " 12    요세      요새  2584\n",
      " 13    금새      금세  3017\n",
      " 14     왠       웬 68412\n",
      " 15    웬지      왠지 66930\n",
      " 16  오랫만에    오랜만에   728\n",
      " 17   일일히     일일이   907\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   199\n",
      "...\n",
      "\r\n",
      "Preprocessing 044.페르소나 대화 for CHAT\r\n",
      "Writing 25572 rows to preprocessed\\CHAT\\044.페르소나 대화.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17110\n",
      "  1  는 커녕     는커녕  1358\n",
      "  2  은 커녕     은커녕  1016\n",
      "  3    라고      라고 60758\n",
      "  4    부터      부터 26099\n",
      "  5   투성이     투성이  2837\n",
      "  6    짜리      짜리  3609\n",
      "  7    어치      어치  1817\n",
      "  8   할려고     하려고  2707\n",
      "  9   어떻해     어떡해   294\n",
      " 10   어짜피     어차피   237\n",
      " 11   곰곰히     곰곰이   695\n",
      " 12    요세      요새  2584\n",
      " 13    금새      금세  3021\n",
      " 14     왠       웬 69161\n",
      " 15    웬지      왠지 67671\n",
      " 16  오랫만에    오랜만에   729\n",
      " 17   일일히     일일이   907\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   199\n",
      "...\n",
      "\r\n",
      "Preprocessing 045.지식검색 대화 for CHAT\r\n",
      "Writing 14622 rows to preprocessed\\CHAT\\045.지식검색 대화.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17115\n",
      "  1  는 커녕     는커녕  1358\n",
      "  2  은 커녕     은커녕  1018\n",
      "  3    라고      라고 60842\n",
      "  4    부터      부터 26230\n",
      "  5   투성이     투성이  2865\n",
      "  6    짜리      짜리  3624\n",
      "  7    어치      어치  1822\n",
      "  8   할려고     하려고  2707\n",
      "  9   어떻해     어떡해   294\n",
      " 10   어짜피     어차피   237\n",
      " 11   곰곰히     곰곰이   696\n",
      " 12    요세      요새  2590\n",
      " 13    금새      금세  3023\n",
      " 14     왠       웬 69813\n",
      " 15    웬지      왠지 68317\n",
      " 16  오랫만에    오랜만에   730\n",
      " 17   일일히     일일이   908\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   199\n",
      "...\n",
      "\r\n",
      "Preprocessing 046.공감형 대화 for CHAT\r\n",
      "Writing 10786 rows to preprocessed\\CHAT\\046.공감형 대화.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17117\n",
      "  1  는 커녕     는커녕  1358\n",
      "  2  은 커녕     은커녕  1018\n",
      "  3    라고      라고 60887\n",
      "  4    부터      부터 26273\n",
      "  5   투성이     투성이  2879\n",
      "  6    짜리      짜리  3626\n",
      "  7    어치      어치  1822\n",
      "  8   할려고     하려고  2707\n",
      "  9   어떻해     어떡해   295\n",
      " 10   어짜피     어차피   238\n",
      " 11   곰곰히     곰곰이   696\n",
      " 12    요세      요새  2590\n",
      " 13    금새      금세  3032\n",
      " 14     왠       웬 70146\n",
      " 15    웬지      왠지 68646\n",
      " 16  오랫만에    오랜만에   732\n",
      " 17   일일히     일일이   909\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   199\n",
      "...\n",
      "\r\n",
      "Preprocessing 048.일반상식 문장 생성 데이터 for CORPUS\r\n",
      "Writing 812992 rows to preprocessed\\CORPUS\\048.일반상식 문장 생성 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17118\n",
      "  1  는 커녕     는커녕  1371\n",
      "  2  은 커녕     은커녕  1032\n",
      "  3    라고      라고 60891\n",
      "  4    부터      부터 26323\n",
      "  5   투성이     투성이  2887\n",
      "  6    짜리      짜리  3627\n",
      "  7    어치      어치  1829\n",
      "  8   할려고     하려고  2712\n",
      "  9   어떻해     어떡해   295\n",
      " 10   어짜피     어차피   238\n",
      " 11   곰곰히     곰곰이   730\n",
      " 12    요세      요새  2590\n",
      " 13    금새      금세  3093\n",
      " 14     왠       웬 70671\n",
      " 15    웬지      왠지 69151\n",
      " 16  오랫만에    오랜만에   764\n",
      " 17   일일히     일일이   915\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   200\n",
      "...\n",
      "\r\n",
      "Preprocessing 053.한국어-다국어(영어 제외) 번역 말뭉치(기술과학) for TASK_TRANSLATION\r\n",
      "Writing 240414 rows to preprocessed\\TASK_TRANSLATION\\053.한국어-다국어(영어 제외) 번역 말뭉치(기술과학).jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17119\n",
      "  1  는 커녕     는커녕  1374\n",
      "  2  은 커녕     은커녕  1034\n",
      "  3    라고      라고 60932\n",
      "  4    부터      부터 26418\n",
      "  5   투성이     투성이  2889\n",
      "  6    짜리      짜리  3628\n",
      "  7    어치      어치  1829\n",
      "  8   할려고     하려고  2712\n",
      "  9   어떻해     어떡해   295\n",
      " 10   어짜피     어차피   238\n",
      " 11   곰곰히     곰곰이   730\n",
      " 12    요세      요새  2594\n",
      " 13    금새      금세  3094\n",
      " 14     왠       웬 70686\n",
      " 15    웬지      왠지 69165\n",
      " 16  오랫만에    오랜만에   764\n",
      " 17   일일히     일일이   915\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   200\n",
      "...\n",
      "\r\n",
      "Preprocessing 054.한국어-다국어 번역 말뭉치(기초과학) for TASK_TRANSLATION\r\n",
      "Writing 240242 rows to preprocessed\\TASK_TRANSLATION\\054.한국어-다국어 번역 말뭉치(기초과학).jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17119\n",
      "  1  는 커녕     는커녕  1375\n",
      "  2  은 커녕     은커녕  1034\n",
      "  3    라고      라고 60950\n",
      "  4    부터      부터 26433\n",
      "  5   투성이     투성이  2890\n",
      "  6    짜리      짜리  3629\n",
      "  7    어치      어치  1832\n",
      "  8   할려고     하려고  2712\n",
      "  9   어떻해     어떡해   295\n",
      " 10   어짜피     어차피   238\n",
      " 11   곰곰히     곰곰이   731\n",
      " 12    요세      요새  2594\n",
      " 13    금새      금세  3094\n",
      " 14     왠       웬 70707\n",
      " 15    웬지      왠지 69187\n",
      " 16  오랫만에    오랜만에   764\n",
      " 17   일일히     일일이   915\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   200\n",
      "...\n",
      "\r\n",
      "Preprocessing 055.한국어-다국어 번역 말뭉치(인문학) for TASK_TRANSLATION\r\n",
      "Writing 241061 rows to preprocessed\\TASK_TRANSLATION\\055.한국어-다국어 번역 말뭉치(인문학).jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17119\n",
      "  1  는 커녕     는커녕  1380\n",
      "  2  은 커녕     은커녕  1034\n",
      "  3    라고      라고 60969\n",
      "  4    부터      부터 26454\n",
      "  5   투성이     투성이  2893\n",
      "  6    짜리      짜리  3630\n",
      "  7    어치      어치  1832\n",
      "  8   할려고     하려고  2712\n",
      "  9   어떻해     어떡해   295\n",
      " 10   어짜피     어차피   238\n",
      " 11   곰곰히     곰곰이   731\n",
      " 12    요세      요새  2597\n",
      " 13    금새      금세  3099\n",
      " 14     왠       웬 70734\n",
      " 15    웬지      왠지 69214\n",
      " 16  오랫만에    오랜만에   764\n",
      " 17   일일히     일일이   915\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   200\n",
      "...\n",
      "\r\n",
      "Preprocessing 119.국가기록물 대상 초거대AI 학습을 위한 말뭉치 데이터 for CORPUS\r\n",
      "Writing 28624 rows to preprocessed\\CORPUS\\119.국가기록물 대상 초거대AI 학습을 위한 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17166\n",
      "  1  는 커녕     는커녕  1401\n",
      "  2  은 커녕     은커녕  1053\n",
      "  3    라고      라고 62131\n",
      "  4    부터      부터 30992\n",
      "  5   투성이     투성이  2901\n",
      "  6    짜리      짜리  3667\n",
      "  7    어치      어치  1893\n",
      "  8   할려고     하려고  2747\n",
      "  9   어떻해     어떡해   297\n",
      " 10   어짜피     어차피   242\n",
      " 11   곰곰히     곰곰이   732\n",
      " 12    요세      요새  2679\n",
      " 13    금새      금세  3171\n",
      " 14     왠       웬 70819\n",
      " 15    웬지      왠지 69289\n",
      " 16  오랫만에    오랜만에   764\n",
      " 17   일일히     일일이   921\n",
      " 18  희안하다    희한하다    18\n",
      " 19   희안한     희한한   200\n",
      "...\n",
      "\r\n",
      "Preprocessing 121.한국어 성능이 개선된 초거대AI 언어모델 개발 및 데이터 for CORPUS\r\n",
      "Writing 2688970 rows to preprocessed\\CORPUS\\121.한국어 성능이 개선된 초거대AI 언어모델 개발 및 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 17301\n",
      "  1  는 커녕     는커녕  1908\n",
      "  2  은 커녕     은커녕  1568\n",
      "  3    라고      라고 86124\n",
      "  4    부터      부터 55637\n",
      "  5   투성이     투성이  3439\n",
      "  6    짜리      짜리  9723\n",
      "  7    어치      어치  2827\n",
      "  8   할려고     하려고  3440\n",
      "  9   어떻해     어떡해   305\n",
      " 10   어짜피     어차피   242\n",
      " 11   곰곰히     곰곰이   750\n",
      " 12    요세      요새  3146\n",
      " 13    금새      금세  3381\n",
      " 14     왠       웬 74176\n",
      " 15    웬지      왠지 72536\n",
      " 16  오랫만에    오랜만에   770\n",
      " 17   일일히     일일이   994\n",
      " 18  희안하다    희한하다    19\n",
      " 19   희안한     희한한   209\n",
      "...\n",
      "\r\n",
      "Preprocessing 141.한국어 멀티세션 대화 for CHAT\r\n",
      "Writing 184000 rows to preprocessed\\CHAT\\141.한국어 멀티세션 대화.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18376\n",
      "  1  는 커녕     는커녕  1947\n",
      "  2  은 커녕     은커녕  1628\n",
      "  3    라고      라고 86784\n",
      "  4    부터      부터 57738\n",
      "  5   투성이     투성이  3520\n",
      "  6    짜리      짜리  9823\n",
      "  7    어치      어치  2835\n",
      "  8   할려고     하려고  4306\n",
      "  9   어떻해     어떡해   337\n",
      " 10   어짜피     어차피   304\n",
      " 11   곰곰히     곰곰이   784\n",
      " 12    요세      요새  3240\n",
      " 13    금새      금세  3624\n",
      " 14     왠       웬 77779\n",
      " 15    웬지      왠지 75316\n",
      " 16  오랫만에    오랜만에  1462\n",
      " 17   일일히     일일이  1021\n",
      " 18  희안하다    희한하다    20\n",
      " 19   희안한     희한한   227\n",
      "...\n",
      "\r\n",
      "Preprocessing 150.숫자연산 기계독해 데이터 for CORPUS\r\n",
      "Writing 331951 rows to preprocessed\\CORPUS\\150.숫자연산 기계독해 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18391\n",
      "  1  는 커녕     는커녕  1999\n",
      "  2  은 커녕     은커녕  1680\n",
      "  3    라고      라고 87007\n",
      "  4    부터      부터 58507\n",
      "  5   투성이     투성이  3553\n",
      "  6    짜리      짜리 10120\n",
      "  7    어치      어치  3736\n",
      "  8   할려고     하려고  4311\n",
      "  9   어떻해     어떡해   337\n",
      " 10   어짜피     어차피   304\n",
      " 11   곰곰히     곰곰이   787\n",
      " 12    요세      요새  3263\n",
      " 13    금새      금세  3644\n",
      " 14     왠       웬 77845\n",
      " 15    웬지      왠지 75372\n",
      " 16  오랫만에    오랜만에  1472\n",
      " 17   일일히     일일이  1027\n",
      " 18  희안하다    희한하다    20\n",
      " 19   희안한     희한한   227\n",
      "...\n",
      "\r\n",
      "Preprocessing 152.기술과학 문서 기계독해 데이터 for CORPUS\r\n",
      "Writing 18270 rows to preprocessed\\CORPUS\\152.기술과학 문서 기계독해 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18391\n",
      "  1  는 커녕     는커녕  1999\n",
      "  2  은 커녕     은커녕  1680\n",
      "  3    라고      라고 87231\n",
      "  4    부터      부터 59053\n",
      "  5   투성이     투성이  3553\n",
      "  6    짜리      짜리 10123\n",
      "  7    어치      어치  3736\n",
      "  8   할려고     하려고  4311\n",
      "  9   어떻해     어떡해   337\n",
      " 10   어짜피     어차피   304\n",
      " 11   곰곰히     곰곰이   787\n",
      " 12    요세      요새  3263\n",
      " 13    금새      금세  3644\n",
      " 14     왠       웬 77845\n",
      " 15    웬지      왠지 75372\n",
      " 16  오랫만에    오랜만에  1472\n",
      " 17   일일히     일일이  1027\n",
      " 18  희안하다    희한하다    20\n",
      " 19   희안한     희한한   227\n",
      "...\n",
      "\r\n",
      "Preprocessing 153.기술과학 요약 데이터 for TASK_SUMMARIZATION\r\n",
      "Writing 96049 rows to preprocessed\\TASK_SUMMARIZATION\\153.기술과학 요약 데이터.jsonl\r\n",
      "Preprocessing 153.기술과학 요약 데이터 for CORPUS\r\n",
      "Writing 96049 rows to preprocessed\\CORPUS\\153.기술과학 요약 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18396\n",
      "  1  는 커녕     는커녕  1999\n",
      "  2  은 커녕     은커녕  1682\n",
      "  3    라고      라고 90867\n",
      "  4    부터      부터 65732\n",
      "  5   투성이     투성이  3557\n",
      "  6    짜리      짜리 10135\n",
      "  7    어치      어치  3736\n",
      "  8   할려고     하려고  4321\n",
      "  9   어떻해     어떡해   337\n",
      " 10   어짜피     어차피   306\n",
      " 11   곰곰히     곰곰이   787\n",
      " 12    요세      요새  3274\n",
      " 13    금새      금세  3644\n",
      " 14     왠       웬 77845\n",
      " 15    웬지      왠지 75372\n",
      " 16  오랫만에    오랜만에  1472\n",
      " 17   일일히     일일이  1033\n",
      " 18  희안하다    희한하다    20\n",
      " 19   희안한     희한한   227\n",
      "...\n",
      "\r\n",
      "Preprocessing 155.산업정보 연계 주요국 특허 영-한 데이터 for TASK_TRANSLATION\r\n",
      "Writing 319997 rows to preprocessed\\TASK_TRANSLATION\\155.산업정보 연계 주요국 특허 영-한 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18409\n",
      "  1  는 커녕     는커녕  1999\n",
      "  2  은 커녕     은커녕  1682\n",
      "  3    라고      라고 90973\n",
      "  4    부터      부터 66664\n",
      "  5   투성이     투성이  3558\n",
      "  6    짜리      짜리 10136\n",
      "  7    어치      어치  3736\n",
      "  8   할려고     하려고  4323\n",
      "  9   어떻해     어떡해   337\n",
      " 10   어짜피     어차피   306\n",
      " 11   곰곰히     곰곰이   787\n",
      " 12    요세      요새  3275\n",
      " 13    금새      금세  3645\n",
      " 14     왠       웬 77845\n",
      " 15    웬지      왠지 75373\n",
      " 16  오랫만에    오랜만에  1472\n",
      " 17   일일히     일일이  1033\n",
      " 18  희안하다    희한하다    20\n",
      " 19   희안한     희한한   227\n",
      "...\n",
      "\r\n",
      "Preprocessing 156.전문분야 영-한, 중-한 번역 말뭉치(식품) for TASK_TRANSLATION\r\n",
      "Writing 2399935 rows to preprocessed\\TASK_TRANSLATION\\156.전문분야 영-한, 중-한 번역 말뭉치(식품).jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18410\n",
      "  1  는 커녕     는커녕  1999\n",
      "  2  은 커녕     은커녕  1683\n",
      "  3    라고      라고 91053\n",
      "  4    부터      부터 66758\n",
      "  5   투성이     투성이  3565\n",
      "  6    짜리      짜리 10140\n",
      "  7    어치      어치  3742\n",
      "  8   할려고     하려고  4323\n",
      "  9   어떻해     어떡해   337\n",
      " 10   어짜피     어차피   306\n",
      " 11   곰곰히     곰곰이   787\n",
      " 12    요세      요새  3284\n",
      " 13    금새      금세  3648\n",
      " 14     왠       웬 77846\n",
      " 15    웬지      왠지 75375\n",
      " 16  오랫만에    오랜만에  1472\n",
      " 17   일일히     일일이  1034\n",
      " 18  희안하다    희한하다    20\n",
      " 19   희안한     희한한   227\n",
      "...\n",
      "\r\n",
      "Preprocessing 157.방송 콘텐츠 한-중, 한-일 번역 병렬 말뭉치 데이터 for TASK_TRANSLATION\r\n",
      "Writing 1273039 rows to preprocessed\\TASK_TRANSLATION\\157.방송 콘텐츠 한-중, 한-일 번역 병렬 말뭉치 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18430\n",
      "  1  는 커녕     는커녕  2024\n",
      "  2  은 커녕     은커녕  1693\n",
      "  3    라고      라고 92161\n",
      "  4    부터      부터 66985\n",
      "  5   투성이     투성이  3608\n",
      "  6    짜리      짜리 10167\n",
      "  7    어치      어치  3754\n",
      "  8   할려고     하려고  4336\n",
      "  9   어떻해     어떡해   340\n",
      " 10   어짜피     어차피   315\n",
      " 11   곰곰히     곰곰이   798\n",
      " 12    요세      요새  3285\n",
      " 13    금새      금세  3668\n",
      " 14     왠       웬 78737\n",
      " 15    웬지      왠지 76246\n",
      " 16  오랫만에    오랜만에  1476\n",
      " 17   일일히     일일이  1034\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   228\n",
      "...\n",
      "\r\n",
      "Preprocessing 157.추상 요약 사실성 검증 데이터 for TASK_SUMMARIZATION\r\n",
      "Writing 81127 rows to preprocessed\\TASK_SUMMARIZATION\\157.추상 요약 사실성 검증 데이터.jsonl\r\n",
      "Preprocessing 157.추상 요약 사실성 검증 데이터 for CORPUS\r\n",
      "Writing 81127 rows to preprocessed\\CORPUS\\157.추상 요약 사실성 검증 데이터.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18441\n",
      "  1  는 커녕     는커녕  2174\n",
      "  2  은 커녕     은커녕  1767\n",
      "  3    라고      라고 92341\n",
      "  4    부터      부터 67720\n",
      "  5   투성이     투성이  3680\n",
      "  6    짜리      짜리 10221\n",
      "  7    어치      어치  3832\n",
      "  8   할려고     하려고  4352\n",
      "  9   어떻해     어떡해   342\n",
      " 10   어짜피     어차피   315\n",
      " 11   곰곰히     곰곰이   802\n",
      " 12    요세      요새  3295\n",
      " 13    금새      금세  3688\n",
      " 14     왠       웬 78810\n",
      " 15    웬지      왠지 76327\n",
      " 16  오랫만에    오랜만에  1482\n",
      " 17   일일히     일일이  1039\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   228\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKLNEWSPAPER_2022_v1.0_JSON.zip for CORPUS\r\n",
      "Writing 978342 rows to preprocessed\\CORPUS\\NIKLNEWSPAPER_2022_v1.0_JSON.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18483\n",
      "  1  는 커녕     는커녕  2415\n",
      "  2  은 커녕     은커녕  1981\n",
      "  3    라고      라고 92574\n",
      "  4    부터      부터 70366\n",
      "  5   투성이     투성이  3818\n",
      "  6    짜리      짜리 10626\n",
      "  7    어치      어치  4872\n",
      "  8   할려고     하려고  4363\n",
      "  9   어떻해     어떡해   343\n",
      " 10   어짜피     어차피   321\n",
      " 11   곰곰히     곰곰이   809\n",
      " 12    요세      요새  3342\n",
      " 13    금새      금세  3815\n",
      " 14     왠       웬 79036\n",
      " 15    웬지      왠지 76555\n",
      " 16  오랫만에    오랜만에  1505\n",
      " 17   일일히     일일이  1075\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   231\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_DIALOGUE_2020_v1.4.zip for CHAT\r\n",
      "Writing 2232 rows to preprocessed\\CHAT\\NIKL_DIALOGUE_2020_v1.4.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18485\n",
      "  1  는 커녕     는커녕  2415\n",
      "  2  은 커녕     은커녕  1982\n",
      "  3    라고      라고 92677\n",
      "  4    부터      부터 70382\n",
      "  5   투성이     투성이  3819\n",
      "  6    짜리      짜리 10643\n",
      "  7    어치      어치  4881\n",
      "  8   할려고     하려고  4428\n",
      "  9   어떻해     어떡해   343\n",
      " 10   어짜피     어차피   321\n",
      " 11   곰곰히     곰곰이   813\n",
      " 12    요세      요새  3344\n",
      " 13    금새      금세  3815\n",
      " 14     왠       웬 79238\n",
      " 15    웬지      왠지 76748\n",
      " 16  오랫만에    오랜만에  1505\n",
      " 17   일일히     일일이  1075\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   231\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_DIALOGUE_2021_v1.1.zip for CHAT\r\n",
      "Writing 3723 rows to preprocessed\\CHAT\\NIKL_DIALOGUE_2021_v1.1.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18490\n",
      "  1  는 커녕     는커녕  2417\n",
      "  2  은 커녕     은커녕  1984\n",
      "  3    라고      라고 93496\n",
      "  4    부터      부터 70536\n",
      "  5   투성이     투성이  3824\n",
      "  6    짜리      짜리 10771\n",
      "  7    어치      어치  4902\n",
      "  8   할려고     하려고  4507\n",
      "  9   어떻해     어떡해   347\n",
      " 10   어짜피     어차피   322\n",
      " 11   곰곰히     곰곰이   820\n",
      " 12    요세      요새  3349\n",
      " 13    금새      금세  3820\n",
      " 14     왠       웬 79578\n",
      " 15    웬지      왠지 77052\n",
      " 16  오랫만에    오랜만에  1505\n",
      " 17   일일히     일일이  1076\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   232\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_DIALOGUE_2022_v1.0_JSON.zip for CHAT\r\n",
      "Writing 2129 rows to preprocessed\\CHAT\\NIKL_DIALOGUE_2022_v1.0_JSON.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18490\n",
      "  1  는 커녕     는커녕  2417\n",
      "  2  은 커녕     은커녕  1984\n",
      "  3    라고      라고 93618\n",
      "  4    부터      부터 70557\n",
      "  5   투성이     투성이  3827\n",
      "  6    짜리      짜리 10815\n",
      "  7    어치      어치  4905\n",
      "  8   할려고     하려고  4557\n",
      "  9   어떻해     어떡해   347\n",
      " 10   어짜피     어차피   322\n",
      " 11   곰곰히     곰곰이   820\n",
      " 12    요세      요새  3349\n",
      " 13    금새      금세  3820\n",
      " 14     왠       웬 79722\n",
      " 15    웬지      왠지 77190\n",
      " 16  오랫만에    오랜만에  1505\n",
      " 17   일일히     일일이  1076\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   232\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_NEWSPAPER_2020_v1.1_JSON.zip for CORPUS\r\n",
      "Writing 580152 rows to preprocessed\\CORPUS\\NIKL_NEWSPAPER_2020_v1.1_JSON.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18534\n",
      "  1  는 커녕     는커녕  2683\n",
      "  2  은 커녕     은커녕  2232\n",
      "  3    라고      라고 94547\n",
      "  4    부터      부터 72932\n",
      "  5   투성이     투성이  3939\n",
      "  6    짜리      짜리 11131\n",
      "  7    어치      어치  5326\n",
      "  8   할려고     하려고  4585\n",
      "  9   어떻해     어떡해   351\n",
      " 10   어짜피     어차피   326\n",
      " 11   곰곰히     곰곰이   833\n",
      " 12    요세      요새  3403\n",
      " 13    금새      금세  3984\n",
      " 14     왠       웬 80244\n",
      " 15    웬지      왠지 77645\n",
      " 16  오랫만에    오랜만에  1531\n",
      " 17   일일히     일일이  1113\n",
      " 18  희안하다    희한하다    21\n",
      " 19   희안한     희한한   238\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_NEWSPAPER_2021_v1.0_JSON.zip for CORPUS\r\n",
      "Writing 729280 rows to preprocessed\\CORPUS\\NIKL_NEWSPAPER_2021_v1.0_JSON.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18589\n",
      "  1  는 커녕     는커녕  3072\n",
      "  2  은 커녕     은커녕  2565\n",
      "  3    라고      라고 95545\n",
      "  4    부터      부터 75459\n",
      "  5   투성이     투성이  4071\n",
      "  6    짜리      짜리 11644\n",
      "  7    어치      어치  6427\n",
      "  8   할려고     하려고  4609\n",
      "  9   어떻해     어떡해   351\n",
      " 10   어짜피     어차피   335\n",
      " 11   곰곰히     곰곰이   857\n",
      " 12    요세      요새  3440\n",
      " 13    금새      금세  4115\n",
      " 14     왠       웬 80808\n",
      " 15    웬지      왠지 78141\n",
      " 16  오랫만에    오랜만에  1570\n",
      " 17   일일히     일일이  1187\n",
      " 18  희안하다    희한하다    22\n",
      " 19   희안한     희한한   244\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_NEWSPAPER_2023_JSON_v1.0.zip for CORPUS\r\n",
      "Writing 1023431 rows to preprocessed\\CORPUS\\NIKL_NEWSPAPER_2023_JSON_v1.0.zip.jsonl\r\n",
      "    wrong correct count\n",
      "  0    몇일      며칠 18625\n",
      "  1  는 커녕     는커녕  3358\n",
      "  2  은 커녕     은커녕  2775\n",
      "  3    라고      라고 96146\n",
      "  4    부터      부터 77776\n",
      "  5   투성이     투성이  4138\n",
      "  6    짜리      짜리 12079\n",
      "  7    어치      어치  7704\n",
      "  8   할려고     하려고  4626\n",
      "  9   어떻해     어떡해   352\n",
      " 10   어짜피     어차피   342\n",
      " 11   곰곰히     곰곰이   864\n",
      " 12    요세      요새  3527\n",
      " 13    금새      금세  4191\n",
      " 14     왠       웬 81050\n",
      " 15    웬지      왠지 78365\n",
      " 16  오랫만에    오랜만에  1592\n",
      " 17   일일히     일일이  1245\n",
      " 18  희안하다    희한하다    23\n",
      " 19   희안한     희한한   247\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_NEWSPAPER_v2.0_JSON.zip for CORPUS\r\n",
      "Writing 3536491 rows to preprocessed\\CORPUS\\NIKL_NEWSPAPER_v2.0_JSON.zip.jsonl\r\n",
      "    wrong correct  count\n",
      "  0    몇일      며칠  19000\n",
      "  1  는 커녕     는커녕   5482\n",
      "  2  은 커녕     은커녕   4548\n",
      "  3    라고      라고 102516\n",
      "  4    부터      부터  89915\n",
      "  5   투성이     투성이   5533\n",
      "  6    짜리      짜리  15257\n",
      "  7    어치      어치  10505\n",
      "  8   할려고     하려고   4765\n",
      "  9   어떻해     어떡해    422\n",
      " 10   어짜피     어차피    400\n",
      " 11   곰곰히     곰곰이   1071\n",
      " 12    요세      요새   4082\n",
      " 13    금새      금세   5221\n",
      " 14     왠       웬  90072\n",
      " 15    웬지      왠지  86741\n",
      " 16  오랫만에    오랜만에   1884\n",
      " 17   일일히     일일이   1641\n",
      " 18  희안하다    희한하다     27\n",
      " 19   희안한     희한한    281\n",
      "...\n",
      "\r\n",
      "Preprocessing NIKL_WRITTEN_v1.2_JSON.zip for CORPUS\r\n",
      "Writing 10045 rows to preprocessed\\CORPUS\\NIKL_WRITTEN_v1.2_JSON.zip.jsonl\r\n",
      "    wrong correct  count\n",
      "  0    몇일      며칠  19115\n",
      "  1  는 커녕     는커녕   5784\n",
      "  2  은 커녕     은커녕   4770\n",
      "  3    라고      라고 105336\n",
      "  4    부터      부터  90866\n",
      "  5   투성이     투성이   6197\n",
      "  6    짜리      짜리  15915\n",
      "  7    어치      어치  10779\n",
      "  8   할려고     하려고   4888\n",
      "  9   어떻해     어떡해    445\n",
      " 10   어짜피     어차피    417\n",
      " 11   곰곰히     곰곰이   1239\n",
      " 12    요세      요새   4313\n",
      " 13    금새      금세   5617\n",
      " 14     왠       웬  93374\n",
      " 15    웬지      왠지  90017\n",
      " 16  오랫만에    오랜만에   1979\n",
      " 17   일일히     일일이   1678\n",
      " 18  희안하다    희한하다     30\n",
      " 19   희안한     희한한    307\n",
      "...\n",
      "\r\n",
      "Preprocessing 기계독해 for CORPUS\r\n",
      "Writing 101844 rows to preprocessed\\CORPUS\\기계독해.jsonl\r\n",
      "    wrong correct  count\n",
      "  0    몇일      며칠  19121\n",
      "  1  는 커녕     는커녕   5861\n",
      "  2  은 커녕     은커녕   4812\n",
      "  3    라고      라고 105619\n",
      "  4    부터      부터  91179\n",
      "  5   투성이     투성이   6213\n",
      "  6    짜리      짜리  16097\n",
      "  7    어치      어치  10957\n",
      "  8   할려고     하려고   4892\n",
      "  9   어떻해     어떡해    446\n",
      " 10   어짜피     어차피    421\n",
      " 11   곰곰히     곰곰이   1239\n",
      " 12    요세      요새   4327\n",
      " 13    금새      금세   5651\n",
      " 14     왠       웬  93502\n",
      " 15    웬지      왠지  90137\n",
      " 16  오랫만에    오랜만에   1988\n",
      " 17   일일히     일일이   1690\n",
      " 18  희안하다    희한하다     30\n",
      " 19   희안한     희한한    309\n",
      "...\n",
      "\r\n",
      "Preprocessing 도서자료 요약 for TASK_SUMMARIZATION\r\n",
      "Writing 160002 rows to preprocessed\\TASK_SUMMARIZATION\\도서자료 요약.jsonl\r\n",
      "Preprocessing 도서자료 요약 for CORPUS\r\n",
      "Writing 160002 rows to preprocessed\\CORPUS\\도서자료 요약.jsonl\r\n",
      "    wrong correct  count\n",
      "  0    몇일      며칠  19127\n",
      "  1  는 커녕     는커녕   5874\n",
      "  2  은 커녕     은커녕   4827\n",
      "  3    라고      라고 106068\n",
      "  4    부터      부터  92012\n",
      "  5   투성이     투성이   6228\n",
      "  6    짜리      짜리  16119\n",
      "  7    어치      어치  10959\n",
      "  8   할려고     하려고   4893\n",
      "  9   어떻해     어떡해    446\n",
      " 10   어짜피     어차피    421\n",
      " 11   곰곰히     곰곰이   1245\n",
      " 12    요세      요새   4331\n",
      " 13    금새      금세   5655\n",
      " 14     왠       웬  93530\n",
      " 15    웬지      왠지  90165\n",
      " 16  오랫만에    오랜만에   1988\n",
      " 17   일일히     일일이   1698\n",
      " 18  희안하다    희한하다     30\n",
      " 19   희안한     희한한    309\n",
      "...\n",
      "\r\n",
      "Preprocessing 문서요약 텍스트 for TASK_SUMMARIZATION\r\n",
      "Writing 325072 rows to preprocessed\\TASK_SUMMARIZATION\\문서요약 텍스트.jsonl\r\n",
      "Preprocessing 문서요약 텍스트 for CORPUS\r\n",
      "Writing 325072 rows to preprocessed\\CORPUS\\문서요약 텍스트.jsonl\r\n",
      "    wrong correct  count\n",
      "  0    몇일      며칠  19130\n",
      "  1  는 커녕     는커녕   5924\n",
      "  2  은 커녕     은커녕   4872\n",
      "  3    라고      라고 106220\n",
      "  4    부터      부터  92914\n",
      "  5   투성이     투성이   6240\n",
      "  6    짜리      짜리  16132\n",
      "  7    어치      어치  11004\n",
      "  8   할려고     하려고   4898\n",
      "  9   어떻해     어떡해    447\n",
      " 10   어짜피     어차피    421\n",
      " 11   곰곰히     곰곰이   1247\n",
      " 12    요세      요새   4335\n",
      " 13    금새      금세   5657\n",
      " 14     왠       웬  93537\n",
      " 15    웬지      왠지  90169\n",
      " 16  오랫만에    오랜만에   1991\n",
      " 17   일일히     일일이   1700\n",
      " 18  희안하다    희한하다     30\n",
      " 19   희안한     희한한    309\n",
      "...\n",
      "\r\n",
      "All files are preprocessed.\r\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T08:12:29.529927500Z",
     "start_time": "2024-11-24T08:12:26.690176900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataFrameOf(\n",
    "    \"wrong\" to commonGrammarMistakes.keys.toList(),\n",
    "    \"correct\" to commonGrammarMistakes.values.toList(),\n",
    "    \"count\" to commonGrammarMistakesStatistics.values.map { it.second }.toList()\n",
    ")"
   ],
   "outputs": [
    {
     "data": {
      "text/html": [
       "            <iframe onload=\"o_resize_iframe_out_1()\" style=\"width:100%;\" class=\"result_container\" id=\"iframe_out_1\" frameBorder=\"0\" srcdoc=\"        &lt;html theme='dark'&gt;\n",
       "        &lt;head&gt;\n",
       "            &lt;style type=&quot;text&sol;css&quot;&gt;\n",
       "                :root {\n",
       "    --background: #fff;\n",
       "    --background-odd: #f5f5f5;\n",
       "    --background-hover: #d9edfd;\n",
       "    --header-text-color: #474747;\n",
       "    --text-color: #848484;\n",
       "    --text-color-dark: #000;\n",
       "    --text-color-medium: #737373;\n",
       "    --text-color-pale: #b3b3b3;\n",
       "    --inner-border-color: #aaa;\n",
       "    --bold-border-color: #000;\n",
       "    --link-color: #296eaa;\n",
       "    --link-color-pale: #296eaa;\n",
       "    --link-hover: #1a466c;\n",
       "}\n",
       "\n",
       ":root[theme=&quot;dark&quot;], :root [data-jp-theme-light=&quot;false&quot;], .dataframe_dark{\n",
       "    --background: #303030;\n",
       "    --background-odd: #3c3c3c;\n",
       "    --background-hover: #464646;\n",
       "    --header-text-color: #dddddd;\n",
       "    --text-color: #b3b3b3;\n",
       "    --text-color-dark: #dddddd;\n",
       "    --text-color-medium: #b2b2b2;\n",
       "    --text-color-pale: #737373;\n",
       "    --inner-border-color: #707070;\n",
       "    --bold-border-color: #777777;\n",
       "    --link-color: #008dc0;\n",
       "    --link-color-pale: #97e1fb;\n",
       "    --link-hover: #00688e;\n",
       "}\n",
       "\n",
       "p.dataframe_description {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "table.dataframe {\n",
       "    font-family: &quot;Helvetica Neue&quot;, Helvetica, Arial, sans-serif;\n",
       "    font-size: 12px;\n",
       "    background-color: var(--background);\n",
       "    color: var(--text-color-dark);\n",
       "    border: none;\n",
       "    border-collapse: collapse;\n",
       "}\n",
       "\n",
       "table.dataframe th, td {\n",
       "    padding: 6px;\n",
       "    border: 1px solid transparent;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       "table.dataframe th {\n",
       "    background-color: var(--background);\n",
       "    color: var(--header-text-color);\n",
       "}\n",
       "\n",
       "table.dataframe td {\n",
       "    vertical-align: top;\n",
       "}\n",
       "\n",
       "table.dataframe th.bottomBorder {\n",
       "    border-bottom-color: var(--bold-border-color);\n",
       "}\n",
       "\n",
       "table.dataframe tbody &gt; tr:nth-child(odd) {\n",
       "    background: var(--background-odd);\n",
       "}\n",
       "\n",
       "table.dataframe tbody &gt; tr:nth-child(even) {\n",
       "    background: var(--background);\n",
       "}\n",
       "\n",
       "table.dataframe tbody &gt; tr:hover {\n",
       "    background: var(--background-hover);\n",
       "}\n",
       "\n",
       "table.dataframe a {\n",
       "    cursor: pointer;\n",
       "    color: var(--link-color);\n",
       "    text-decoration: none;\n",
       "}\n",
       "\n",
       "table.dataframe tr:hover &gt; td a {\n",
       "    color: var(--link-color-pale);\n",
       "}\n",
       "\n",
       "table.dataframe a:hover {\n",
       "    color: var(--link-hover);\n",
       "    text-decoration: underline;\n",
       "}\n",
       "\n",
       "table.dataframe img {\n",
       "    max-width: fit-content;\n",
       "}\n",
       "\n",
       "table.dataframe th.complex {\n",
       "    background-color: var(--background);\n",
       "    border: 1px solid var(--background);\n",
       "}\n",
       "\n",
       "table.dataframe .leftBorder {\n",
       "    border-left-color: var(--inner-border-color);\n",
       "}\n",
       "\n",
       "table.dataframe .rightBorder {\n",
       "    border-right-color: var(--inner-border-color);\n",
       "}\n",
       "\n",
       "table.dataframe .rightAlign {\n",
       "    text-align: right;\n",
       "}\n",
       "\n",
       "table.dataframe .expanderSvg {\n",
       "    width: 8px;\n",
       "    height: 8px;\n",
       "    margin-right: 3px;\n",
       "}\n",
       "\n",
       "table.dataframe .expander {\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "&sol;* formatting *&sol;\n",
       "\n",
       "table.dataframe .null {\n",
       "    color: var(--text-color-pale);\n",
       "}\n",
       "\n",
       "table.dataframe .structural {\n",
       "    color: var(--text-color-medium);\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       "table.dataframe .dataFrameCaption {\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       "table.dataframe .numbers {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "table.dataframe td:hover .formatted .structural, .null {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "table.dataframe tr:hover .formatted .structural, .null {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "\n",
       ":root {\n",
       "    --scroll-bg: #f5f5f5;\n",
       "    --scroll-fg: #b3b3b3;\n",
       "}\n",
       ":root[theme=&quot;dark&quot;], :root [data-jp-theme-light=&quot;false&quot;]{\n",
       "    --scroll-bg: #3c3c3c;\n",
       "    --scroll-fg: #97e1fb;\n",
       "}\n",
       "body {\n",
       "    scrollbar-color: var(--scroll-fg) var(--scroll-bg);\n",
       "}\n",
       "body::-webkit-scrollbar {\n",
       "    width: 10px; &sol;* Mostly for vertical scrollbars *&sol;\n",
       "    height: 10px; &sol;* Mostly for horizontal scrollbars *&sol;\n",
       "}\n",
       "body::-webkit-scrollbar-thumb {\n",
       "    background-color: var(--scroll-fg);\n",
       "}\n",
       "body::-webkit-scrollbar-track {\n",
       "    background-color: var(--scroll-bg);\n",
       "}\n",
       "            &lt;&sol;style&gt;\n",
       "        &lt;&sol;head&gt;\n",
       "        &lt;body&gt;\n",
       "            &lt;table class=&quot;dataframe&quot; id=&quot;df_-1744830464&quot;&gt;&lt;&sol;table&gt;\n",
       "\n",
       "&lt;p class=&quot;dataframe_description&quot;&gt;... showing only top 20 of 43 rows&lt;&sol;p&gt;&lt;p class=&quot;dataframe_description&quot;&gt;DataFrame: rowsCount = 43, columnsCount = 3&lt;&sol;p&gt;\n",
       "\n",
       "        &lt;&sol;body&gt;\n",
       "        &lt;script&gt;\n",
       "            (function () {\n",
       "    window.DataFrame = window.DataFrame || new (function () {\n",
       "        this.addTable = function (df) {\n",
       "            let cols = df.cols;\n",
       "            for (let i = 0; i &lt; cols.length; i++) {\n",
       "                for (let c of cols[i].children) {\n",
       "                    cols[c].parent = i;\n",
       "                }\n",
       "            }\n",
       "            df.nrow = 0\n",
       "            for (let i = 0; i &lt; df.cols.length; i++) {\n",
       "                if (df.cols[i].values.length &gt; df.nrow) df.nrow = df.cols[i].values.length\n",
       "            }\n",
       "            if (df.id === df.rootId) {\n",
       "                df.expandedFrames = new Set()\n",
       "                df.childFrames = {}\n",
       "                const table = this.getTableElement(df.id)\n",
       "                table.df = df\n",
       "                for (let i = 0; i &lt; df.cols.length; i++) {\n",
       "                    let col = df.cols[i]\n",
       "                    if (col.parent === undefined &amp;&amp; col.children.length &gt; 0) col.expanded = true\n",
       "                }\n",
       "            } else {\n",
       "                const rootDf = this.getTableData(df.rootId)\n",
       "                rootDf.childFrames[df.id] = df\n",
       "            }\n",
       "        }\n",
       "\n",
       "        this.computeRenderData = function (df) {\n",
       "            let result = []\n",
       "            let pos = 0\n",
       "            for (let col = 0; col &lt; df.cols.length; col++) {\n",
       "                if (df.cols[col].parent === undefined)\n",
       "                    pos += this.computeRenderDataRec(df.cols, col, pos, 0, result, false, false)\n",
       "            }\n",
       "            for (let i = 0; i &lt; result.length; i++) {\n",
       "                let row = result[i]\n",
       "                for (let j = 0; j &lt; row.length; j++) {\n",
       "                    let cell = row[j]\n",
       "                    if (j === 0)\n",
       "                        cell.leftBd = false\n",
       "                    if (j &lt; row.length - 1) {\n",
       "                        let nextData = row[j + 1]\n",
       "                        if (nextData.leftBd) cell.rightBd = true\n",
       "                        else if (cell.rightBd) nextData.leftBd = true\n",
       "                    } else cell.rightBd = false\n",
       "                }\n",
       "            }\n",
       "            return result\n",
       "        }\n",
       "\n",
       "        this.computeRenderDataRec = function (cols, colId, pos, depth, result, leftBorder, rightBorder) {\n",
       "            if (result.length === depth) {\n",
       "                const array = [];\n",
       "                if (pos &gt; 0) {\n",
       "                    let j = 0\n",
       "                    for (let i = 0; j &lt; pos; i++) {\n",
       "                        let c = result[depth - 1][i]\n",
       "                        j += c.span\n",
       "                        let copy = Object.assign({empty: true}, c)\n",
       "                        array.push(copy)\n",
       "                    }\n",
       "                }\n",
       "                result.push(array)\n",
       "            }\n",
       "            const col = cols[colId];\n",
       "            let size = 0;\n",
       "            if (col.expanded) {\n",
       "                let childPos = pos\n",
       "                for (let i = 0; i &lt; col.children.length; i++) {\n",
       "                    let child = col.children[i]\n",
       "                    let childLeft = i === 0 &amp;&amp; (col.children.length &gt; 1 || leftBorder)\n",
       "                    let childRight = i === col.children.length - 1 &amp;&amp; (col.children.length &gt; 1 || rightBorder)\n",
       "                    let childSize = this.computeRenderDataRec(cols, child, childPos, depth + 1, result, childLeft, childRight)\n",
       "                    childPos += childSize\n",
       "                    size += childSize\n",
       "                }\n",
       "            } else {\n",
       "                for (let i = depth + 1; i &lt; result.length; i++)\n",
       "                    result[i].push({id: colId, span: 1, leftBd: leftBorder, rightBd: rightBorder, empty: true})\n",
       "                size = 1\n",
       "            }\n",
       "            let left = leftBorder\n",
       "            let right = rightBorder\n",
       "            if (size &gt; 1) {\n",
       "                left = true\n",
       "                right = true\n",
       "            }\n",
       "            result[depth].push({id: colId, span: size, leftBd: left, rightBd: right})\n",
       "            return size\n",
       "        }\n",
       "\n",
       "        this.getTableElement = function (id) {\n",
       "            return document.getElementById(&quot;df_&quot; + id)\n",
       "        }\n",
       "\n",
       "        this.getTableData = function (id) {\n",
       "            return this.getTableElement(id).df\n",
       "        }\n",
       "\n",
       "        this.createExpander = function (isExpanded) {\n",
       "            const svgNs = &quot;http:&sol;&sol;www.w3.org&sol;2000&sol;svg&quot;\n",
       "            let svg = document.createElementNS(svgNs, &quot;svg&quot;)\n",
       "            svg.classList.add(&quot;expanderSvg&quot;)\n",
       "            let path = document.createElementNS(svgNs, &quot;path&quot;)\n",
       "            if (isExpanded) {\n",
       "                svg.setAttribute(&quot;viewBox&quot;, &quot;0 -2 8 8&quot;)\n",
       "                path.setAttribute(&quot;d&quot;, &quot;M1 0 l-1 1 4 4 4 -4 -1 -1 -3 3Z&quot;)\n",
       "            } else {\n",
       "                svg.setAttribute(&quot;viewBox&quot;, &quot;-2 0 8 8&quot;)\n",
       "                path.setAttribute(&quot;d&quot;, &quot;M1 0 l-1 1 3 3 -3 3 1 1 4 -4Z&quot;)\n",
       "            }\n",
       "            path.setAttribute(&quot;fill&quot;, &quot;currentColor&quot;)\n",
       "            svg.appendChild(path)\n",
       "            return svg\n",
       "        }\n",
       "\n",
       "        this.renderTable = function (id) {\n",
       "\n",
       "            let table = this.getTableElement(id)\n",
       "\n",
       "            if (table === null) return\n",
       "\n",
       "            table.innerHTML = &quot;&quot;\n",
       "\n",
       "            let df = table.df\n",
       "            let rootDf = df.rootId === df.id ? df : this.getTableData(df.rootId)\n",
       "\n",
       "            &sol;&sol; header\n",
       "            let header = document.createElement(&quot;thead&quot;)\n",
       "            table.appendChild(header)\n",
       "\n",
       "            let renderData = this.computeRenderData(df)\n",
       "            for (let j = 0; j &lt; renderData.length; j++) {\n",
       "                let rowData = renderData[j]\n",
       "                let tr = document.createElement(&quot;tr&quot;);\n",
       "                let isLastRow = j === renderData.length - 1\n",
       "                header.appendChild(tr);\n",
       "                for (let i = 0; i &lt; rowData.length; i++) {\n",
       "                    let cell = rowData[i]\n",
       "                    let th = document.createElement(&quot;th&quot;);\n",
       "                    th.setAttribute(&quot;colspan&quot;, cell.span)\n",
       "                    let colId = cell.id\n",
       "                    let col = df.cols[colId];\n",
       "                    if (!cell.empty) {\n",
       "                        if (col.children.length === 0) {\n",
       "                            th.innerHTML = col.name\n",
       "                        } else {\n",
       "                            let link = document.createElement(&quot;a&quot;)\n",
       "                            link.className = &quot;expander&quot;\n",
       "                            let that = this\n",
       "                            link.onclick = function () {\n",
       "                                col.expanded = !col.expanded\n",
       "                                that.renderTable(id)\n",
       "                            }\n",
       "                            link.appendChild(this.createExpander(col.expanded))\n",
       "                            link.innerHTML += col.name\n",
       "                            th.appendChild(link)\n",
       "                        }\n",
       "                    }\n",
       "                    let classes = (cell.leftBd ? &quot; leftBorder&quot; : &quot;&quot;) + (cell.rightBd ? &quot; rightBorder&quot; : &quot;&quot;)\n",
       "                    if (col.rightAlign)\n",
       "                        classes += &quot; rightAlign&quot;\n",
       "                    if (isLastRow)\n",
       "                        classes += &quot; bottomBorder&quot;\n",
       "                    if (classes.length &gt; 0)\n",
       "                        th.setAttribute(&quot;class&quot;, classes)\n",
       "                    tr.appendChild(th)\n",
       "                }\n",
       "            }\n",
       "\n",
       "            &sol;&sol; body\n",
       "            let body = document.createElement(&quot;tbody&quot;)\n",
       "            table.appendChild(body)\n",
       "\n",
       "            let columns = renderData.pop()\n",
       "            for (let row = 0; row &lt; df.nrow; row++) {\n",
       "                let tr = document.createElement(&quot;tr&quot;);\n",
       "                body.appendChild(tr)\n",
       "                for (let i = 0; i &lt; columns.length; i++) {\n",
       "                    let cell = columns[i]\n",
       "                    let td = document.createElement(&quot;td&quot;);\n",
       "                    let colId = cell.id\n",
       "                    let col = df.cols[colId]\n",
       "                    let classes = (cell.leftBd ? &quot; leftBorder&quot; : &quot;&quot;) + (cell.rightBd ? &quot; rightBorder&quot; : &quot;&quot;)\n",
       "                    if (col.rightAlign)\n",
       "                        classes += &quot; rightAlign&quot;\n",
       "                    if (classes.length &gt; 0)\n",
       "                        td.setAttribute(&quot;class&quot;, classes)\n",
       "                    tr.appendChild(td)\n",
       "                    let value = col.values[row]\n",
       "                    if (value.frameId !== undefined) {\n",
       "                        let frameId = value.frameId\n",
       "                        let expanded = rootDf.expandedFrames.has(frameId)\n",
       "                        let link = document.createElement(&quot;a&quot;)\n",
       "                        link.className = &quot;expander&quot;\n",
       "                        let that = this\n",
       "                        link.onclick = function () {\n",
       "                            if (rootDf.expandedFrames.has(frameId))\n",
       "                                rootDf.expandedFrames.delete(frameId)\n",
       "                            else rootDf.expandedFrames.add(frameId)\n",
       "                            that.renderTable(id)\n",
       "                        }\n",
       "                        link.appendChild(this.createExpander(expanded))\n",
       "                        link.innerHTML += value.value\n",
       "                        if (expanded) {\n",
       "                            td.appendChild(link)\n",
       "                            td.appendChild(document.createElement(&quot;p&quot;))\n",
       "                            const childTable = document.createElement(&quot;table&quot;)\n",
       "                            childTable.className = &quot;dataframe&quot;\n",
       "                            childTable.id = &quot;df_&quot; + frameId\n",
       "                            let childDf = rootDf.childFrames[frameId]\n",
       "                            childTable.df = childDf\n",
       "                            td.appendChild(childTable)\n",
       "                            this.renderTable(frameId)\n",
       "                            if (childDf.nrow !== childDf.totalRows) {\n",
       "                                const footer = document.createElement(&quot;p&quot;)\n",
       "                                footer.innerText = `... showing only top ${childDf.nrow} of ${childDf.totalRows} rows`\n",
       "                                td.appendChild(footer)\n",
       "                            }\n",
       "                        } else {\n",
       "                            td.appendChild(link)\n",
       "                        }\n",
       "                    } else if (value.style !== undefined) {\n",
       "                        td.innerHTML = value.value\n",
       "                        td.setAttribute(&quot;style&quot;, value.style)\n",
       "                    } else td.innerHTML = value\n",
       "                    this.nodeScriptReplace(td)\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "\n",
       "        this.nodeScriptReplace = function (node) {\n",
       "            if (this.nodeScriptIs(node) === true) {\n",
       "                node.parentNode.replaceChild(this.nodeScriptClone(node), node);\n",
       "            } else {\n",
       "                let i = -1, children = node.childNodes;\n",
       "                while (++i &lt; children.length) {\n",
       "                    this.nodeScriptReplace(children[i]);\n",
       "                }\n",
       "            }\n",
       "\n",
       "            return node;\n",
       "        }\n",
       "\n",
       "        this.nodeScriptClone = function (node) {\n",
       "            let script = document.createElement(&quot;script&quot;);\n",
       "            script.text = node.innerHTML;\n",
       "\n",
       "            let i = -1, attrs = node.attributes, attr;\n",
       "            while (++i &lt; attrs.length) {\n",
       "                script.setAttribute((attr = attrs[i]).name, attr.value);\n",
       "            }\n",
       "            return script;\n",
       "        }\n",
       "\n",
       "        this.nodeScriptIs = function (node) {\n",
       "            return node.tagName === 'SCRIPT';\n",
       "        }\n",
       "    })()\n",
       "\n",
       "    window.call_DataFrame = function (f) {\n",
       "        return f();\n",
       "    };\n",
       "\n",
       "    let funQueue = window[&quot;kotlinQueues&quot;] &amp;&amp; window[&quot;kotlinQueues&quot;][&quot;DataFrame&quot;];\n",
       "    if (funQueue) {\n",
       "        funQueue.forEach(function (f) {\n",
       "            f();\n",
       "        });\n",
       "        funQueue = [];\n",
       "    }\n",
       "})()\n",
       "\n",
       "&sol;*&lt;!--*&sol;\n",
       "call_DataFrame(function() { DataFrame.addTable({ cols: [{ name: &quot;&lt;span title=&bsol;&quot;wrong: String&bsol;&quot;&gt;wrong&lt;&sol;span&gt;&quot;, children: [], rightAlign: false, values: [&quot;&amp;#47751;&amp;#51068;&quot;,&quot;&amp;#45716; &amp;#52964;&amp;#45397;&quot;,&quot;&amp;#51008; &amp;#52964;&amp;#45397;&quot;,&quot; &amp;#46972;&amp;#44256;&quot;,&quot; &amp;#48512;&amp;#53552;&quot;,&quot; &amp;#53804;&amp;#49457;&amp;#51060;&quot;,&quot; &amp;#51676;&amp;#47532;&quot;,&quot; &amp;#50612;&amp;#52824;&quot;,&quot;&amp;#54624;&amp;#47140;&amp;#44256;&quot;,&quot;&amp;#50612;&amp;#46523;&amp;#54644;&quot;,&quot;&amp;#50612;&amp;#51676;&amp;#54588;&quot;,&quot;&amp;#44272;&amp;#44272;&amp;#55176;&quot;,&quot;&amp;#50836;&amp;#49464;&quot;,&quot;&amp;#44552;&amp;#49352;&quot;,&quot;&amp;#50784;&quot;,&quot;&amp;#50924;&amp;#51648;&quot;,&quot;&amp;#50724;&amp;#47019;&amp;#47564;&amp;#50640;&quot;,&quot;&amp;#51068;&amp;#51068;&amp;#55176;&quot;,&quot;&amp;#55148;&amp;#50504;&amp;#54616;&amp;#45796;&quot;,&quot;&amp;#55148;&amp;#50504;&amp;#54620;&quot;] }, \n",
       "{ name: &quot;&lt;span title=&bsol;&quot;correct: String&bsol;&quot;&gt;correct&lt;&sol;span&gt;&quot;, children: [], rightAlign: false, values: [&quot;&amp;#47728;&amp;#52832;&quot;,&quot;&amp;#45716;&amp;#52964;&amp;#45397;&quot;,&quot;&amp;#51008;&amp;#52964;&amp;#45397;&quot;,&quot;&amp;#46972;&amp;#44256;&quot;,&quot;&amp;#48512;&amp;#53552;&quot;,&quot;&amp;#53804;&amp;#49457;&amp;#51060;&quot;,&quot;&amp;#51676;&amp;#47532;&quot;,&quot;&amp;#50612;&amp;#52824;&quot;,&quot;&amp;#54616;&amp;#47140;&amp;#44256;&quot;,&quot;&amp;#50612;&amp;#46497;&amp;#54644;&quot;,&quot;&amp;#50612;&amp;#52264;&amp;#54588;&quot;,&quot;&amp;#44272;&amp;#44272;&amp;#51060;&quot;,&quot;&amp;#50836;&amp;#49352;&quot;,&quot;&amp;#44552;&amp;#49464;&quot;,&quot;&amp;#50924;&quot;,&quot;&amp;#50784;&amp;#51648;&quot;,&quot;&amp;#50724;&amp;#47004;&amp;#47564;&amp;#50640;&quot;,&quot;&amp;#51068;&amp;#51068;&amp;#51060;&quot;,&quot;&amp;#55148;&amp;#54620;&amp;#54616;&amp;#45796;&quot;,&quot;&amp;#55148;&amp;#54620;&amp;#54620;&quot;] }, \n",
       "{ name: &quot;&lt;span title=&bsol;&quot;count: Int&bsol;&quot;&gt;count&lt;&sol;span&gt;&quot;, children: [], rightAlign: true, values: [&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;19130&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;5924&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;4872&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;106220&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;92914&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;6240&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;16132&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;11004&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;4898&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;447&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;421&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;1247&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;4335&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;5657&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;93537&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;90169&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;1991&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;1700&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;30&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;,&quot;&lt;span class=&bsol;&quot;formatted&bsol;&quot; title=&bsol;&quot;&bsol;&quot;&gt;&lt;span class=&bsol;&quot;numbers&bsol;&quot;&gt;309&lt;&sol;span&gt;&lt;&sol;span&gt;&quot;] }, \n",
       "], id: -1744830464, rootId: -1744830464, totalRows: 43 } ) });\n",
       "&sol;*--&gt;*&sol;\n",
       "\n",
       "call_DataFrame(function() { DataFrame.renderTable(-1744830464) });\n",
       "\n",
       "\n",
       "        &lt;&sol;script&gt;\n",
       "        &lt;&sol;html&gt;\"></iframe>\n",
       "            <script>\n",
       "                function o_resize_iframe_out_1() {\n",
       "                    let elem = document.getElementById(\"iframe_out_1\");\n",
       "                    resize_iframe_out_1(elem);\n",
       "                    setInterval(resize_iframe_out_1, 5000, elem);\n",
       "                }\n",
       "                function resize_iframe_out_1(el) {\n",
       "                    let h = el.contentWindow.document.body.scrollHeight;\n",
       "                    el.height = h === 0 ? 0 : h + 41;\n",
       "                }\n",
       "            </script>        <html theme='dark'>\n",
       "        <head>\n",
       "            <style type=\"text/css\">\n",
       "                :root {\n",
       "    --background: #fff;\n",
       "    --background-odd: #f5f5f5;\n",
       "    --background-hover: #d9edfd;\n",
       "    --header-text-color: #474747;\n",
       "    --text-color: #848484;\n",
       "    --text-color-dark: #000;\n",
       "    --text-color-medium: #737373;\n",
       "    --text-color-pale: #b3b3b3;\n",
       "    --inner-border-color: #aaa;\n",
       "    --bold-border-color: #000;\n",
       "    --link-color: #296eaa;\n",
       "    --link-color-pale: #296eaa;\n",
       "    --link-hover: #1a466c;\n",
       "}\n",
       "\n",
       ":root[theme=\"dark\"], :root [data-jp-theme-light=\"false\"], .dataframe_dark{\n",
       "    --background: #303030;\n",
       "    --background-odd: #3c3c3c;\n",
       "    --background-hover: #464646;\n",
       "    --header-text-color: #dddddd;\n",
       "    --text-color: #b3b3b3;\n",
       "    --text-color-dark: #dddddd;\n",
       "    --text-color-medium: #b2b2b2;\n",
       "    --text-color-pale: #737373;\n",
       "    --inner-border-color: #707070;\n",
       "    --bold-border-color: #777777;\n",
       "    --link-color: #008dc0;\n",
       "    --link-color-pale: #97e1fb;\n",
       "    --link-hover: #00688e;\n",
       "}\n",
       "\n",
       "p.dataframe_description {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "table.dataframe {\n",
       "    font-family: \"Helvetica Neue\", Helvetica, Arial, sans-serif;\n",
       "    font-size: 12px;\n",
       "    background-color: var(--background);\n",
       "    color: var(--text-color-dark);\n",
       "    border: none;\n",
       "    border-collapse: collapse;\n",
       "}\n",
       "\n",
       "table.dataframe th, td {\n",
       "    padding: 6px;\n",
       "    border: 1px solid transparent;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       "table.dataframe th {\n",
       "    background-color: var(--background);\n",
       "    color: var(--header-text-color);\n",
       "}\n",
       "\n",
       "table.dataframe td {\n",
       "    vertical-align: top;\n",
       "}\n",
       "\n",
       "table.dataframe th.bottomBorder {\n",
       "    border-bottom-color: var(--bold-border-color);\n",
       "}\n",
       "\n",
       "table.dataframe tbody > tr:nth-child(odd) {\n",
       "    background: var(--background-odd);\n",
       "}\n",
       "\n",
       "table.dataframe tbody > tr:nth-child(even) {\n",
       "    background: var(--background);\n",
       "}\n",
       "\n",
       "table.dataframe tbody > tr:hover {\n",
       "    background: var(--background-hover);\n",
       "}\n",
       "\n",
       "table.dataframe a {\n",
       "    cursor: pointer;\n",
       "    color: var(--link-color);\n",
       "    text-decoration: none;\n",
       "}\n",
       "\n",
       "table.dataframe tr:hover > td a {\n",
       "    color: var(--link-color-pale);\n",
       "}\n",
       "\n",
       "table.dataframe a:hover {\n",
       "    color: var(--link-hover);\n",
       "    text-decoration: underline;\n",
       "}\n",
       "\n",
       "table.dataframe img {\n",
       "    max-width: fit-content;\n",
       "}\n",
       "\n",
       "table.dataframe th.complex {\n",
       "    background-color: var(--background);\n",
       "    border: 1px solid var(--background);\n",
       "}\n",
       "\n",
       "table.dataframe .leftBorder {\n",
       "    border-left-color: var(--inner-border-color);\n",
       "}\n",
       "\n",
       "table.dataframe .rightBorder {\n",
       "    border-right-color: var(--inner-border-color);\n",
       "}\n",
       "\n",
       "table.dataframe .rightAlign {\n",
       "    text-align: right;\n",
       "}\n",
       "\n",
       "table.dataframe .expanderSvg {\n",
       "    width: 8px;\n",
       "    height: 8px;\n",
       "    margin-right: 3px;\n",
       "}\n",
       "\n",
       "table.dataframe .expander {\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "}\n",
       "\n",
       "/* formatting */\n",
       "\n",
       "table.dataframe .null {\n",
       "    color: var(--text-color-pale);\n",
       "}\n",
       "\n",
       "table.dataframe .structural {\n",
       "    color: var(--text-color-medium);\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       "table.dataframe .dataFrameCaption {\n",
       "    font-weight: bold;\n",
       "}\n",
       "\n",
       "table.dataframe .numbers {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "table.dataframe td:hover .formatted .structural, .null {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "table.dataframe tr:hover .formatted .structural, .null {\n",
       "    color: var(--text-color-dark);\n",
       "}\n",
       "\n",
       "\n",
       "            </style>\n",
       "        </head>\n",
       "        <body>\n",
       "            <table class=\"dataframe\" id=\"static_df_-1744830463\"><thead><tr><th class=\"bottomBorder\" style=\"text-align:left\">wrong</th><th class=\"bottomBorder\" style=\"text-align:left\">correct</th><th class=\"bottomBorder\" style=\"text-align:left\">count</th></tr></thead><tbody><tr><td  style=\"vertical-align:top\">&#47751;&#51068;</td><td  style=\"vertical-align:top\">&#47728;&#52832;</td><td  style=\"vertical-align:top\">19130</td></tr><tr><td  style=\"vertical-align:top\">&#45716; &#52964;&#45397;</td><td  style=\"vertical-align:top\">&#45716;&#52964;&#45397;</td><td  style=\"vertical-align:top\">5924</td></tr><tr><td  style=\"vertical-align:top\">&#51008; &#52964;&#45397;</td><td  style=\"vertical-align:top\">&#51008;&#52964;&#45397;</td><td  style=\"vertical-align:top\">4872</td></tr><tr><td  style=\"vertical-align:top\"> &#46972;&#44256;</td><td  style=\"vertical-align:top\">&#46972;&#44256;</td><td  style=\"vertical-align:top\">106220</td></tr><tr><td  style=\"vertical-align:top\"> &#48512;&#53552;</td><td  style=\"vertical-align:top\">&#48512;&#53552;</td><td  style=\"vertical-align:top\">92914</td></tr><tr><td  style=\"vertical-align:top\"> &#53804;&#49457;&#51060;</td><td  style=\"vertical-align:top\">&#53804;&#49457;&#51060;</td><td  style=\"vertical-align:top\">6240</td></tr><tr><td  style=\"vertical-align:top\"> &#51676;&#47532;</td><td  style=\"vertical-align:top\">&#51676;&#47532;</td><td  style=\"vertical-align:top\">16132</td></tr><tr><td  style=\"vertical-align:top\"> &#50612;&#52824;</td><td  style=\"vertical-align:top\">&#50612;&#52824;</td><td  style=\"vertical-align:top\">11004</td></tr><tr><td  style=\"vertical-align:top\">&#54624;&#47140;&#44256;</td><td  style=\"vertical-align:top\">&#54616;&#47140;&#44256;</td><td  style=\"vertical-align:top\">4898</td></tr><tr><td  style=\"vertical-align:top\">&#50612;&#46523;&#54644;</td><td  style=\"vertical-align:top\">&#50612;&#46497;&#54644;</td><td  style=\"vertical-align:top\">447</td></tr><tr><td  style=\"vertical-align:top\">&#50612;&#51676;&#54588;</td><td  style=\"vertical-align:top\">&#50612;&#52264;&#54588;</td><td  style=\"vertical-align:top\">421</td></tr><tr><td  style=\"vertical-align:top\">&#44272;&#44272;&#55176;</td><td  style=\"vertical-align:top\">&#44272;&#44272;&#51060;</td><td  style=\"vertical-align:top\">1247</td></tr><tr><td  style=\"vertical-align:top\">&#50836;&#49464;</td><td  style=\"vertical-align:top\">&#50836;&#49352;</td><td  style=\"vertical-align:top\">4335</td></tr><tr><td  style=\"vertical-align:top\">&#44552;&#49352;</td><td  style=\"vertical-align:top\">&#44552;&#49464;</td><td  style=\"vertical-align:top\">5657</td></tr><tr><td  style=\"vertical-align:top\">&#50784;</td><td  style=\"vertical-align:top\">&#50924;</td><td  style=\"vertical-align:top\">93537</td></tr><tr><td  style=\"vertical-align:top\">&#50924;&#51648;</td><td  style=\"vertical-align:top\">&#50784;&#51648;</td><td  style=\"vertical-align:top\">90169</td></tr><tr><td  style=\"vertical-align:top\">&#50724;&#47019;&#47564;&#50640;</td><td  style=\"vertical-align:top\">&#50724;&#47004;&#47564;&#50640;</td><td  style=\"vertical-align:top\">1991</td></tr><tr><td  style=\"vertical-align:top\">&#51068;&#51068;&#55176;</td><td  style=\"vertical-align:top\">&#51068;&#51068;&#51060;</td><td  style=\"vertical-align:top\">1700</td></tr><tr><td  style=\"vertical-align:top\">&#55148;&#50504;&#54616;&#45796;</td><td  style=\"vertical-align:top\">&#55148;&#54620;&#54616;&#45796;</td><td  style=\"vertical-align:top\">30</td></tr><tr><td  style=\"vertical-align:top\">&#55148;&#50504;&#54620;</td><td  style=\"vertical-align:top\">&#55148;&#54620;&#54620;</td><td  style=\"vertical-align:top\">309</td></tr></tbody></table>\n",
       "        </body>\n",
       "        <script>\n",
       "            document.getElementById(\"static_df_-1744830463\").style.display = \"none\";\n",
       "        </script>\n",
       "        </html>"
      ],
      "application/kotlindataframe+json": "{\"$version\":\"2.1.1\",\"metadata\":{\"columns\":[\"wrong\",\"correct\",\"count\"],\"types\":[{\"kind\":\"ValueColumn\",\"type\":\"kotlin.String\"},{\"kind\":\"ValueColumn\",\"type\":\"kotlin.String\"},{\"kind\":\"ValueColumn\",\"type\":\"kotlin.Int\"}],\"nrow\":43,\"ncol\":3},\"kotlin_dataframe\":[{\"wrong\":\"몇일\",\"correct\":\"며칠\",\"count\":19130},{\"wrong\":\"는 커녕\",\"correct\":\"는커녕\",\"count\":5924},{\"wrong\":\"은 커녕\",\"correct\":\"은커녕\",\"count\":4872},{\"wrong\":\" 라고\",\"correct\":\"라고\",\"count\":106220},{\"wrong\":\" 부터\",\"correct\":\"부터\",\"count\":92914},{\"wrong\":\" 투성이\",\"correct\":\"투성이\",\"count\":6240},{\"wrong\":\" 짜리\",\"correct\":\"짜리\",\"count\":16132},{\"wrong\":\" 어치\",\"correct\":\"어치\",\"count\":11004},{\"wrong\":\"할려고\",\"correct\":\"하려고\",\"count\":4898},{\"wrong\":\"어떻해\",\"correct\":\"어떡해\",\"count\":447},{\"wrong\":\"어짜피\",\"correct\":\"어차피\",\"count\":421},{\"wrong\":\"곰곰히\",\"correct\":\"곰곰이\",\"count\":1247},{\"wrong\":\"요세\",\"correct\":\"요새\",\"count\":4335},{\"wrong\":\"금새\",\"correct\":\"금세\",\"count\":5657},{\"wrong\":\"왠\",\"correct\":\"웬\",\"count\":93537},{\"wrong\":\"웬지\",\"correct\":\"왠지\",\"count\":90169},{\"wrong\":\"오랫만에\",\"correct\":\"오랜만에\",\"count\":1991},{\"wrong\":\"일일히\",\"correct\":\"일일이\",\"count\":1700},{\"wrong\":\"희안하다\",\"correct\":\"희한하다\",\"count\":30},{\"wrong\":\"희안한\",\"correct\":\"희한한\",\"count\":309}]}"
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kotlin",
   "language": "kotlin",
   "name": "kotlin"
  },
  "language_info": {
   "name": "kotlin",
   "version": "1.9.23",
   "mimetype": "text/x-kotlin",
   "file_extension": ".kt",
   "pygments_lexer": "kotlin",
   "codemirror_mode": "text/x-kotlin",
   "nbconvert_exporter": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
